{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 740M\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import theano\n",
    "import theano.tensor.signal.downsample\n",
    "from common.plotting import plot_mat\n",
    "from utils import *\n",
    "import time\n",
    "\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing ('features', 'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "from prepare_cifar10 import *\n",
    "\n",
    "cifar = prepare_cifar10()\n",
    "\n",
    "cifar_train = cifar.train\n",
    "cifar_train_stream = cifar.train_stream\n",
    "                                               \n",
    "cifar_validation = cifar.validation\n",
    "cifar_validation_stream = cifar.validation_stream\n",
    "\n",
    "cifar_test = cifar.test\n",
    "cifar_test_stream = cifar.test_stream\n",
    "\n",
    "print(\"The streams return batches containing %s\" % (cifar_train_stream.sources,))\n",
    "\n",
    "print(\"Each trainin batch consits of a tuple containing:\")\n",
    "for element in next(cifar_train_stream.get_epoch_iterator()):\n",
    "    print(\" - an array of size %s containing %s\" % (element.shape, element.dtype))\n",
    "    \n",
    "print(\"Validation/test batches consits of tuples containing:\")\n",
    "for element in next(cifar_test_stream.get_epoch_iterator()):\n",
    "    print(\" - an array of size %s containing %s\" % (element.shape, element.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def conv2D(num_in_filters, num_out_filters, kernel_size, name = None):\n",
    "    name = name if name else fresh_name(\"?\")\n",
    "        \n",
    "    weights_shape = (num_out_filters, num_in_filters, kernel_size, kernel_size)\n",
    "    weights_name = \"{}.weights\".format(name)\n",
    "    weights = theano.shared(np.zeros(weights_shape, dtype = 'float32'), name = weights_name)\n",
    "    weights.tag.initializer = IsotropicGaussian(0.05)\n",
    "    \n",
    "    biases_shape = (num_out_filters,)\n",
    "    biases_name = \"{}.biases\".format(name)\n",
    "    biases = theano.shared(np.zeros(biases_shape, dtype='float32'), biases_name)\n",
    "    biases.tag.initializer = Constant(0.0)\n",
    "    \n",
    "    def fprop(X):\n",
    "        return theano.tensor.nnet.conv2d(X, weights) + biases.dimshuffle('x', 0, 'x', 'x')\n",
    "    \n",
    "    fprop.params = [weights, biases]\n",
    "    \n",
    "    return fprop\n",
    "\n",
    "def relu(name = fresh_name(\"?\")):\n",
    "    def fprop(X):\n",
    "        return theano.tensor.maximum(0.0, X)\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def max_pool_2d(kernel_size):\n",
    "    def fprop(X):\n",
    "        kernel_shape = (kernel_size, kernel_size)\n",
    "        return theano.tensor.signal.downsample.max_pool_2d(X, kernel_shape, ignore_border = True)\n",
    "\n",
    "    return fprop\n",
    "\n",
    "def flatten(name = None):\n",
    "    def fprop(X):\n",
    "        return X.flatten(2)\n",
    "\n",
    "    return fprop\n",
    "    \n",
    "def xaffine(num_inputs, num_outputs, name = None):    \n",
    "    name = name if name else fresh_name(\"?\")\n",
    "    \n",
    "    weights_shape = (num_inputs, num_outputs)\n",
    "    weights_name = \"{}.weights\".format(name)\n",
    "    weights = theano.shared(np.zeros(weights_shape, dtype='float32'), name = weights_name)\n",
    "    weights.tag.initializer = IsotropicGaussian(0.05)\n",
    "    \n",
    "    biases_shape = (num_outputs, )\n",
    "    biases_name = \"{}.biases\".format(name)\n",
    "    biases = theano.shared(np.zeros(biases_shape, dtype='float32'), name = biases_name)\n",
    "    biases.tag.initializer = Constant(0.0)\n",
    "    \n",
    "    def fprop(X):\n",
    "        return theano.tensor.dot(X, weights) + biases.dimshuffle('x', 0)\n",
    "\n",
    "    fprop.params = [weights, biases]\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def maxout(num_inputs, num_outputs, degree, name = None):\n",
    "    name = name if name else fresh_name(\"?\")\n",
    "    \n",
    "    weights_shape = (num_outputs, num_inputs, degree)\n",
    "    weights_name = \"{}.weights\".format(name)\n",
    "    weights = theano.shared(np.zeros(weights_shape, dtype='float32'), name = weights_name)\n",
    "    weights.tag.initializer = IsotropicGaussian(0.05)\n",
    "    \n",
    "    biases_shape = (num_outputs, degree)\n",
    "    biases_name = \"{}.biases\".format(name)\n",
    "    biases = theano.shared(np.zeros(biases_shape, dtype='float32'), name = biases_name)\n",
    "    biases.tag.initializer = Constant(0.0)\n",
    "    \n",
    "    def fprop(X):\n",
    "        return theano.tensor.max(theano.tensor.dot(X, weights) + biases.dimshuffle('x', 0, 1), axis = 2)\n",
    "    \n",
    "    fprop.params = [weights, biases]\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def softmax():\n",
    "    def fprop(X):\n",
    "        return theano.tensor.nnet.softmax(X)\n",
    "\n",
    "    return fprop\n",
    "    \n",
    "def compose(*args):\n",
    "    def fprop(X):\n",
    "        for arg in args:\n",
    "            X = arg(X)\n",
    "        return X\n",
    "    \n",
    "    params = []\n",
    "\n",
    "    for arg in args:\n",
    "        try:\n",
    "            params += arg.params\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    \n",
    "    if params != []:\n",
    "        fprop.params = params\n",
    "    \n",
    "    return fprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile(template):\n",
    "    X = theano.tensor.tensor4('X', dtype = 'float32')\n",
    "    Y = theano.tensor.matrix('Y', dtype = 'uint8')\n",
    "    \n",
    "    model_parameters = template.params\n",
    "\n",
    "    log_probs = template(X)\n",
    "\n",
    "    predictions = theano.tensor.argmax(log_probs, axis = 1)\n",
    "\n",
    "    error_rate = theano.tensor.neq(predictions,Y.ravel()).mean()\n",
    "    nll = - theano.tensor.log(log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()\n",
    "\n",
    "    weight_decay = 0.0\n",
    "    for p in model_parameters:\n",
    "        if p.name.endswith('weights'):\n",
    "            weight_decay = weight_decay + 1e-3 * (p ** 2).sum()\n",
    "\n",
    "    cost = nll + weight_decay\n",
    "    \n",
    "    learn_rate = theano.tensor.scalar('learn_rate', dtype = 'float32')\n",
    "    momentum = theano.tensor.scalar('momentum', dtype = 'float32')\n",
    "\n",
    "    # Theano will compute the gradients for us\n",
    "    gradients = theano.grad(cost, model_parameters)\n",
    "\n",
    "    #initialize storage for momentum\n",
    "    velocities = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in model_parameters]\n",
    "    \n",
    "    updates = []\n",
    "\n",
    "    for p, g, v in zip(model_parameters, gradients, velocities):\n",
    "        if p.name.endswith(\"weights\"):\n",
    "            g += 1e-3 * p\n",
    "        v_new = momentum * v - learn_rate * g\n",
    "        p_new = p + v_new\n",
    "        updates += [(v, v_new), (p, p_new)]\n",
    "            \n",
    "    def step_ex(X, Y, learn_rate, momentum):\n",
    "        return step(X, Y, learn_rate, momentum)\n",
    "    \n",
    "    def init_parameters():\n",
    "        rng = numpy.random.RandomState(1234)\n",
    "        \n",
    "        for p in model_parameters:\n",
    "            p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "            \n",
    "        for v in velocities:\n",
    "            v.set_value(np.zeros_like(v.get_value()))\n",
    "            \n",
    "    step = theano.function(\n",
    "        [X, Y, learn_rate, momentum],\n",
    "        [cost, error_rate, nll, weight_decay],\n",
    "        updates = updates, \n",
    "        allow_input_downcast = True)\n",
    "            \n",
    "    predict = theano.function([X], predictions)\n",
    "    \n",
    "    init_parameters()\n",
    "    \n",
    "    class Network:\n",
    "        def snapshot(self):\n",
    "            return [p.get_value(borrow = False) for p in self.params]\n",
    "    \n",
    "        def load(self, snapshot):\n",
    "            for p, s in zip(self.params, snapshot):\n",
    "                p.set_value(s, borrow = False)\n",
    "    \n",
    "    network = Network()\n",
    "    network.step = step_ex\n",
    "    network.predict = predict\n",
    "    network.params = model_parameters\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(network, learn_rate0, momentum):\n",
    "    batch = 0\n",
    "    epoch = 0\n",
    "\n",
    "    best_valid_error_rate = np.inf\n",
    "    best_params = network.snapshot()\n",
    "    best_params_epoch = 0\n",
    "\n",
    "    train_erros = []\n",
    "    train_loss = []\n",
    "    train_nll = []\n",
    "    validation_errors = []\n",
    "\n",
    "    number_of_epochs = 3\n",
    "    patience_expansion = 1.5\n",
    "\n",
    "    # training loop\n",
    "    try:\n",
    "        start = time.time()\n",
    "        \n",
    "        while epoch < number_of_epochs: #This loop goes over epochs\n",
    "            epoch += 1\n",
    "            #First train on all data from this batch\n",
    "\n",
    "            epoch_start_batch = batch\n",
    "\n",
    "            for X_batch, Y_batch in cifar_train_stream.get_epoch_iterator(): \n",
    "                batch += 1\n",
    "\n",
    "                # learn_rate = learn_rate0 * (1 - np.tanh(batch * 0.549306 / 2000))\n",
    "                \n",
    "                K = 2000\n",
    "                learn_rate = learn_rate0 * K / np.maximum(K, batch)\n",
    "                \n",
    "                L, err_rate, nll, wdec = network.step(X_batch, Y_batch, learn_rate, momentum)\n",
    "\n",
    "                train_loss.append((batch, L))\n",
    "                train_erros.append((batch, err_rate))\n",
    "                train_nll.append((batch, nll))\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    end = time.time()\n",
    "                    elapsed = end - start\n",
    "                    start = end\n",
    "                    format = \"At minibatch %d, batch loss %f, batch nll %f, batch error rate %f%%, time %.2fms\"\n",
    "                    print(format % (batch, L, nll, err_rate * 100, elapsed / Y_batch.shape[0] * 1000), flush = True)\n",
    "\n",
    "            # After an epoch compute validation error\n",
    "            val_error_rate = compute_error_rate(cifar_validation_stream, network.predict)\n",
    "            if val_error_rate < best_valid_error_rate:\n",
    "                number_of_epochs = np.maximum(number_of_epochs, epoch * patience_expansion + 1)\n",
    "                best_valid_error_rate = val_error_rate\n",
    "                best_params = network.snapshot()\n",
    "                best_params_epoch = epoch\n",
    "            validation_errors.append((batch, val_error_rate))\n",
    "\n",
    "            print(\"After epoch %d: valid_err_rate: %f%% currently going to do %d epochs\" %(\n",
    "                epoch, val_error_rate * 100, number_of_epochs))\n",
    "            print(\"After epoch %d: averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" %(\n",
    "                epoch, np.mean(np.asarray(train_erros)[epoch_start_batch:, 1]) * 100, \n",
    "                np.mean(np.asarray(train_nll)[epoch_start_batch:, 1]),\n",
    "                np.mean(np.asarray(train_loss)[epoch_start_batch:, 1])))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Setting network parameters from after epoch %d\" %(best_params_epoch))\n",
    "        network.load(best_params)\n",
    "        \n",
    "        subplot(2,1,1)\n",
    "        train_nll_a = np.array(train_nll)\n",
    "        semilogy(train_nll_a[:,0], train_nll_a[:,1], label='batch train nll')\n",
    "        legend()\n",
    "\n",
    "        subplot(2,1,2)\n",
    "        train_erros_a = np.array(train_erros)\n",
    "        plot(train_erros_a[:,0], train_erros_a[:,1], label='batch train error rate')\n",
    "        validation_errors_a = np.array(validation_errors)\n",
    "        plot(validation_errors_a[:,0], validation_errors_a[:,1], label='validation error rate', color='r')\n",
    "        ylim(0,0.2)\n",
    "        legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling... DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nn = compose(conv2D(3, 32, 5), \n",
    "             relu(), \n",
    "             max_pool_2d(2),\n",
    "             conv2D(32, 10, 3),\n",
    "             relu(),\n",
    "             flatten(),\n",
    "             maxout(1440, 128, 4),\n",
    "             maxout(128, 10, 4),\n",
    "             softmax()\n",
    "            )\n",
    "\n",
    "print(\"Compiling...\", end = \" \", flush = True)\n",
    "network = compile(nn)\n",
    "print(\"DONE\", flush = True)\n",
    "\n",
    "train(network, 4e-3, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate is 27.890000%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Test error rate is %f%%\" %(compute_error_rate(cifar_test_stream, network.predict) * 100.0,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADRCAYAAAAHfuOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXl0VeXVxs9NyDzP80TCHBAQAyKTIgg4omipI6WOdWzF\nOrQOtWpbrWidWqciatWigCgCCiKDEAgECAlDCBnIHDLPc+7357ee+2Stcy+rWd937PP773nXc7Pv\ncO7OWXvf9902u91uCCGEsAZu/9dPQAghhPMoaQshhIVQ0hZCCAuhpC2EEBZCSVsIISyEkrYQQlgI\nJW0hhLAQStpCCGEhhg11gJUP3A+7d0571ZInotAbdPjlC8kTOXMc6KWjxpvGtu9cTWvNoZ2gj1Q1\nkMe7og90RWcrea771Uum8R/+4FPQNed5k6eq53zQbu3+5Gn2bAGdNSPZNPbwh56hNbfPT4BurT9L\nnuS4HtBhCYGgN+3YbBr7nl8/SmsX/uxm0BNigsnjXlII+hd/e5s8B9d9SmsU/8k7Qd+UdDl5Pm4v\nBf3vx14lT190BOjW4n2msVfu2kVrVZlZoA+s+Y48PWn4VfQP9yTPd29+aRo/Y/n9oIM8B0BfO+pW\nekxQbAboLUUV5Pnw8XjT2C3HcKNe+8BG8nS1jwF9qqCPPLNS8Lr0mTHLNPbP33yZ1oK34fX0w9Fc\n8jSewdd6/VM/J88bTz1vGj/0CfyOhp1pJs/ICMx9uwpKyZPafhj04R+esTl6dKcthBAWQklbCCEs\nhJK2EEJYiCGvaTeVYR0pyDeKPNXxXqATQgPJ0+k11uXYr+YdprVjbWGgf+7lR55TQVhGKt510uXY\nhmEYp4obQe9rjiXPQHwV6HrPDPIEeXa4HDto3Q+0drYaa2i2qGLy1HXPwefX0uty7LBwX1q7NADr\nwwOdfB28selr0Af3HXc5tmEYRmzlKdD9N1xFnhVBi0Fv2sz184os8xq2IxfbzqO1ve5Yo20OTyPP\nloN7Qbu1BLgc2zAM42x9DujTB6eC7gqlEqkR5nUEtFdp3jnF3rPtA9ANrfwZH7jaA/S4riDyrCrn\ner4ZjVu5T5BZj/XqOxY9QZ7Z00eDbmlZQ543nIg/NQB7Y55RSeQ5VlwE2qOlnjxHZnM/wRHdaQsh\nhIVQ0hZCCAuhpC2EEBZiyGvaJYXZoGNGTCfPBL9JoNtCw8mTEur6/5e12UdpLSynGvT7MXPJE5mO\ndfi04ea/Ex2MGH930FEDXMOqbYgD7R7CvwlvyXP9Y1r26DRaGxMwD/S8MfPIk9OF9czqQnzOC5Zt\nM42dGhFHa33JPqDPbOffM5ccxt+AB3Ryv4HfHWb3KYz1M/c28nQl4PU0Nuxq8pT2O/6OnX/X7sjE\nqHJay0uLBN2en06ecUfxlXnU5pCnxDS6YZS0XgR6/G34OlPs3B9pt1eCboyY7EQk5suzeL3XD1xI\nntiOfozVcYA8W7342jVji3cZrd3hMxH0E49dQZ6jWTWg/3zTJpdjG4ZhnM3E/lVrSCZ5WmscavWB\nO8mzsNr8CtedthBCWAglbSGEsBBK2kIIYSGUtIUQwkIMeSOywxebQF6+vPnALw03vPgf8yHPiT7z\nH5074tbCDZWiMbjBJPdr3jgTWIENpxvne5DHGQLj8XCqWQZvrqnpw+cz4M0bC1ouwA0R3zsR22cY\nf7Td/Xhg1Y62deQ5tAcP/WkdxgdqmWH3i+bFwkMgC84eJMvJ6nbQEZ5F5HGmEdk7kA96R343eRZF\nYIP1qlHDyVNZi420o99tMI29JZeb39423Cgzxd+LPPkhiaBbY5r4jx/iv+1IQG0y6OnxeD2l7eTv\nVtYU3OAV8NkZ0ziD0V2Lh1N1Rr1CnoFTj4B+9p+8kS6u8jOXY98bzNdcVMNtoLM/42tu81d4wNYB\nvzr+405cdN4+74CusPMBWy9MwcOxuqO5Meo/t5/WHNGdthBCWAglbSGEsBBK2kIIYSGGvKYd5D0B\n9ECEnTwePimgm8I6yRNScYrWzPDyaqe1aDccphBz2QB5DvbjsICjh3iThzP41WENst6D69Xt4Xgg\nU0uPO3mCMltozYzaXD6E/WA+HiJVa2dPcx9uEhg9mjeCmOHewAcO/bgJN5gU1fFhXiHB+HmlD59I\nnqIvt5jGDwzEzT2FmVwL/lcX3q/0JfF7MbMM66TmFWXDsB/nzSvVvdiP8eriTVZXeBSA3tHEw0Kc\nYfTVeFCRr0Pss0ux3m8YhnFN7RLQP4QOdr09bhr7oMNraNjCB2NNbS8BPS3oAfJsy4kxjeXI6Nhl\ntNayaCvo3y7ha6fADzfbrbj2IvI8svor0/jX7cHCd/iDfNBafCvmkcCQavLkr3PIcxlLyaM7bSGE\nsBBK2kIIYSGUtIUQwkIoaQshhIWw2e3cGPyPBrDZhjaAEEL8RLHb7ZrGLoQQVkZJWwghLISSthBC\nWAglbSGEsBBK2kIIYSGUtIUQwkIoaQshhIVQ0hZCCAsx5Kf8bV2FUyie28wj6v1qcf/NX15cRp6d\nm74Dfd/TfzGNvejRjzlWCE5vOV3LJ4pV78H/ZQklPEkjq/pvpvHvmvNL0B5NpeTZW7cD9NHyseSJ\nf3Qh6JK//Nk09vG3V9NaSweewpYTGkSeuQEYvzwTT+Ob89LvTWO/8sv7aC0lCmMl9HSRJzgSp7cc\nDQ4lz+I7bzGN/9CTOEXk9Mmd5Fl022zQHjv5xLXaPnyOT7zygmnsC8cF09rInlGgR90xkzwx7hmg\ne/359Mk77+IT3xyZO2o86AVz8aTEpsN8emBBVQnoCxcvIs+vX1lpGvud9btBZ7Znkidvbxlo21ev\nk6c1BdPSid195HHkwVsepbWAscmgI/t5glFUbDhod2++5pbcyO+HIytvvh306Ri+Dib2hIBui+F7\n5gaDpxo5ojttIYSwEEraQghhIZS0hRDCQgx5TTt+Gk6CaFrLNaz8aqyzpSevIE9mZAqtmRGZHEdr\n3Yk42WNWMf/dU8OyQLePuJH/+EfmNe3Ft0aBrmqPJE/tepyOfWiAJ4uMyMVJJyWmkQ0jNNCb1s4M\nmwPas4X/Z3fFYqwaX9f/r8/xSaW1wPHYt0gxJpHnhGcx6NG5XGd2hopmnDyU6MevYck8rPW+sfol\n8jQnj6M1M7qPca1+bwROAR/rv5g8I2KvB721+xOXYxuGYfzuGZwu7j9jNOgLTnLN9J2X3wJ91V2X\nkseZmnbxCZx61N/L6SUoHz/jurHjyXP9ZPyOPrt7o2nsdzbzJKThpXj9HMvl2nikzWG6VQhPMHKG\n/THYgxhWVUOewj6cajQ2kr8nQZN8aM0R3WkLIYSFUNIWQggLoaQthBAWQklbCCEsxJA3In1Dsfjv\naXBzsPr0GdCttf7k8UnxdDl2zbo8Wuu5oQf0qcxvyBPs3QK6oJd/KO8MI8ZjsysuP4c8uaOwGZFg\n5wZGaUegy7Gf/uOntFbUiO/hVls5edJH+oEOOnHW5dj9s/nz6xiGAzjWdR4hT/2ZKtD5/bzBxBnS\nBrCZ0x8RRp5hnrGgNx4rIM+CUWNcjt2dHkVriXmtoO3be8lT/wRuOok7MpE8zvDP3P2gpzSfBH3a\ncwQ95v1ybNiF7G0hjzMUdv4LtHc3N3KXXpUGevZN75OnfFcF6GcN80bkHctvpbWGoq9A9wSXkce9\nCa/3Rl9u4DvD+HBsnn67Yz95jhxYD3rzRl/yjMvAJvDyhXeTR3faQghhIZS0hRDCQihpCyGEhRjy\nmnZ5Bf5YfVwc14xqY6JBF5b9SJ7+sn6XYxcUvEdr9ffPBz0srpA8Z4ejHnmG/7dV0QrTX4N1LfsI\nfg0T9uPa+jPDyTMs8rQT0ZDx982jtdgOrGmnDOOa7czJ2IPIP5QNes9DD5vG/ihrH62Vl2H9PHtY\nE3macjB2QAwNonaKkOF48FR1fwl58nfge1px/Ax54pe73ks434vr5/v8cMNNqR/3EmILMX5HtOvX\nu2EYxqEs7EGkpWA/Jqg7gB6TVYrf0ZK+c0sLoYF4sNKF7lzfX7LsMtDuJfXk2dNjfmiSI49fwd/R\n6IQ/gt6XzRtwTrVh/6Vgy2byPHfUPH7qjBmgF8bwxpkDr+NGorKuveTpcuP3wxHdaQshhIVQ0hZC\nCAuhpC2EEBZCSVsIISzEkDci68tyQUeMjibPrCY8HWx3Hm+ksfUVuRw7NJgbIbUllaDtLdwYja48\nAPqs7dx+cB8+FX8oH1LC/yP7sS9j/N6LT/nLrMRNJsf2bTCN7TuNTxT0bMVNE5HejeSJz8AmXlc1\nf15mbKqvoLWKbg/QAzXciOzywUZkbBJvBHGGSC9sZOV/z89na8P3oGdNn02elFF8Ap0ZAUkTaG2a\nkQw6qj6BPAeOY5PMx4s3oTlD6FXpoGsSsPE4z5jGDzofN310Brt+uqFhGMZ5CXNA942zk+f0thLQ\n+wP5hwD+Va5vpHtzDf/oIHHiIdBxdm4AR7RgM74ylCfXOENrJX63p0/gUyyX/ngT6MwC/sGFbS1/\n/x3RnbYQQlgIJW0hhLAQStpCCGEhbHY7153+owFstqENIIQQP1HsdjvtMNOdthBCWAglbSGEsBBK\n2kIIYSGUtIUQwkIoaQshhIVQ0hZCCAuhpC2EEBZCSVsIISzEkB8Ytf3gGtBBo3vI0+83GnVrN3ly\nKnBa9t1jlpnGXuqbQmvn3/An0DPGzyDPrvDtoM+8ylNN3jr8pGn8w3/AQ2x8AwaZrrEEDwZyL+Hp\n55tzcXL59fe+bBo7902eHrOupxT0oc/58CCP2XgwV0BYHehVK5aYxr5q2Qpamx+PU6WTp5aQpyQT\nn3NOPk/xeHftK6bx//4hHhD13H1/J89ra3F6d/yOZvJ8sgevg7/teNQ09r9m3UxrhcF4MFdwKX/G\nlfk4QaUryIc8r1ZvMo1/z4uPgM78AKexl14VTo+5sxUnpP/yYp4APmIJT+Rx5Pwf8IAtz85T5ElM\nvBH0tv0l5JmWiPtJvpm3nTyO3H4fT2NPrQgC3dPTTp4RXo6HwZWS58Z15tPgV36wFvTa/UfIk/0l\nHvTW1cN5JXR8Oq05ojttIYSwEEraQghhIZS0hRDCQihpCyGEhRjyRmS/0Qq6q50bPtU/4hSTrkCe\nWOJX2UprZrR0dNBaxVGcWFJ3oTt55vtfA/qb8d/wHz/MS44cGKgCHR0QRB6//Pmg+2fxcw6qDXBY\nMW9ErgjcTGv1bk+DjrriQfIkn5wK+tIwnHazyjSyYQRM5Kkdk2bEgnY/xo97t/ZZ0K3lxU5EG4RU\nvJ6ah3FDLNReA3r49Z3k6Sg6SWtmJPeU0NqwPmziTUjzJU9NMTbot8XwtWJUm8fvr8Jr5chNOA3o\nfhtPZvk8EKe3XFZ0btNbetp6QdtT+J6wIQSbsvX5ueSpTeLrxzR2QyytpRd/B9qny488QQl7caGN\npwo5w9FMzBFBTZXkWTYX3+eQZn6dZV39prF0py2EEBZCSVsIISyEkrYQQliIIa9pv1uExUv31TwB\nvLYdN1G4VX9OHp9IfpwZXRfH0FrxiY9Bn9jBP3A3FoWATF++lD0f/tw0/poPsa41OaOEPLF3b0Xd\newF5vHtoeIUpofu4Lnmj/6ugPxxxFXmqOo+D/sMJ3iRgxthoD1oLnIxr5fVc1C4px/piS0wfeZxh\nwlncEDShoYY8ca1Yw/aL5pqof3EirZmRP9xxs4ZhJNTge9hVwBtc/O0YK6nVsY/hHFU7sTb+8ytn\ngl44YRY9xvMf+F7kXfn6OcX2jsDvm1dvCHnOVDlMGw8bIM/ES7CnlWVsJY8jl1dvobVEN5zqHtLF\n9fOEMqwhV9h4Q5czHPwX9soy4i8iz29fvg90ygjesLTxiyzTWLrTFkIIC6GkLYQQFkJJWwghLISS\nthBCWIghb0Ru/NtR0LH+3PjrzMSCfFgIn/I3ENDlcuwbE6Np7Ycy3LSwOb+KPKX+B0FflJHkcmzD\nMIxSH9zUkf1v/nF/y5ivQY8tH0Meez83VM3I3H2A1srSIkB39PJ7ao/DS2LGCHy/Dr5vHjsgYDqt\nefTiJp2cCt7wYq8IBj1tKm9CKR7kFDZH4h1OSrwwnhuj7Sew4eTTmEaekGjXvx5NBjdPw/3x+XiP\n5ybj6ARskjV5DnK9nzaPP/zdZNDfP2AHfcf+f9BjrrwC34tr5nMj8n7jAdPYVYfwdMXYVP78pk7A\nhm97GH/XT3zTZhrLEXv4cFo7OYDv+2S/QPLk1uF3ojHZTh7jhPnGvrkLcZPc2ElR5Pnr+rdAlxdy\nMz46ZizoKww+NVJ32kIIYSGUtIUQwkIoaQshhIUY8pp2hw2nWWR48QFNfXFeoOOi/cnT1I1PNc/g\nmqgjAQG8OeKCmbjRIW8LHxDTVoUTQo43LjaNNRizg64EXeexgTx1hwccPPy66kO47m7G6Gh+XYVl\n2aALtnJt9Y5ll4L2rHCsT79qmBESxM83rxA3fWTXlpAn5ma8hwiu4zrzYJNFHPGMxjp86sII8nTG\nYG21dckh8gwvMD+8x5GTrVw3bfbFnkhpRRF51nbjQWG+ocHkcYbi3xSCLpu0DfS4GL6WayauBv3l\n1c+dU+wkG9Zx62v5/evJxw0v/TX8fg07O8hpYiasSeKNPBHTsBadfWAheaLicSPWaXcv8jjTTOjw\nwFr48Vw+MOpQMW4sGhaQTB7/Du6/OKI7bSGEsBBK2kIIYSGUtIUQwkIoaQshhIWw2e2D/Jj8PxnA\nZhvaAEII8RPFbrfTEZ+60xZCCAuhpC2EEBZCSVsIISyEkrYQQlgIJW0hhLAQStpCCGEhlLSFEMJC\nKGkLIYSFGPJT/vqzcArGD6N4skdz2yWgq4uPkCc2G0+/W/zg86axn/52Oa2l5OPpdy0hPN2mtqgR\nn58bn0z42pOPmsb/9HfzQL99Ioc8S29+FvQVi8eSZ/mVq0B/t3EVeRypWPN3Wpv//A7QQXU8NeT3\nf7gX9JZT60C/9iL/XUc2refpKLkNePJfXACfvBcVhSe1JdXwlKORNzxhGv+yy/4CemxqNXnSUmaC\nbqvuIU9NQx7olavMT7/bU8+TRj4NaABdvYNj+fvgZJ8DZxaR59jNz5jGv3jUg6Bb83GC0cSLJtFj\nnv/kr6CDAzrI4xUaRmuO/PUZ/DtVNXwi45QJ+L6nzU8nz66N34B++MEVprFv/Rm/7w89htdK+fEs\n8qzMwes7ttOHPJ+8/m/T+NPSbgXdmXweeVJmTcHHuJ8lz9ebCkxj6U5bCCEshJK2EEJYCCVtIYSw\nEENe087xwhrRQCVPJE85jrXLa4u45veBfwOtmRFUGU5rDf5YS+08Wkierhj8XxZScm7/2/r98bUf\nP8g1rJBrUHee4ckVvWV5tGZGedJIWhuT/zToY+lcPw/rmgq6qNi8nudIw4z5tOa5AevnDZVcXwzy\nRM/BvbUuxzYMw5iQin2TlEh+ne3peOk3xvBnU/1v1ycGFWdl09r1M6eBzs+JIc+a2ThlZbofTz5x\nZp5L6qxI0Pcs/zNod0+eLL7+t1gznjz5AiciMbGxOA1oXyVP6Fm98knQz9t+S557fvEb0M7UtN95\n/yNa+zZnPeirX+J+yKQQPM9u/FKujTtD2vwFoL3tF5Inxj8OdEgLf8aJ6Y205ojutIUQwkIoaQsh\nhIVQ0hZCCAuhpC2EEBZiyBuR7fv6QR+YyD86v9nTE3SzVyB5SnO3uRzbPTCU1uyVvaCP15wkT00p\nPm5kSCR5nOFs+2jQAQn8GvoiO0F7JsaTpz3eoXnLe3SIjAbeONPT5Q26qYobYhPGYPNtypfYJN5o\nHtrorw2hta++2wDap5M3cCy/CZtCPcW8EcsZAr3x80u/hDdQ7Ww4BLron+vJ0zXD4Z7ma/PYHu/y\nRp6QPdjs9lnBn036TtxM831apnmwQbjrNmyITQ4YA3pL9UF6jP/+AdBfrzbfQDUYM+Zgo23OtUvJ\ns+J6fO13PcCb5OpaXR929flXX9HaC0//CXTkAL/vt/0Bm55ToiaT53XjJdP49acrQG+ObCLPyALc\nbFRQyD+C8Dzm+LnfQR7daQshhIVQ0hZCCAuhpC2EEBZiyGvaez7eBzq5lzcf5I3CGuSWygDy5GS7\nvsnjTM4ArRVmYe0yv5UPLlrkPQ70LTO5xv6WE/H9k7GG5T/gRZ6sFvy/mbqbN51Euic6EQ0p6S+h\ntcYIX9DDe0+RZ6cdN/fUxHJfwIzMVW/T2g8lWCu/+8oJ5BntgTXR4wl7XY5tGIZxz7wM0IeSeEPJ\n3pextrsnmw8pu/fyX4D+yjhEHkeO23lzhN8E3GTiscGXPLNuxdfa9BH3NnJNoxuG31k8cGjHbjww\nqq+SD3FqmIifud9wPlTKOL7fNPbbH2PR/5Zr+MC2D77ADS4Jvx5Fnsy1u01jOfLGp4/T2rBxWMN+\ncvnt5Jkenww699AJl2MbhmHkduOmtJHxfMhc5PhZoJttvOkrKp2vDUd0py2EEBZCSVsIISyEkrYQ\nQlgIJW0hhLAQQ96ILBifBtqn8HLy1AQdBR0b8i15eoKwKbTLMJ/esv3zd2mt7QROrrnkcm6IPX4p\nTpwJn2LeHBiM/lZshCy8MJU8Idl40teZBbzhJfhih8fxPgKi5jh/tGNH4iamnsZg8vicxPd+ZDtv\nSDDjkoVTaS2+E08qfOJ2bkC11OWDLq9Icjm2YRhG5QJs+BZ8u488R05iwzc8gZu9U86b7rBifs25\nPbKQ1j75GjdVZVw+hTxNT9+Gz+f3bfzHb+UlR06U4gmZ4wZq8Pml8fXeFICbPGIHmdTkDE3txaD/\n+SZvnLlqMb6IW+7npufaL22gN/LHRwwE9NPatYl4jc1L5pP3vs+vA71++wfmwQbB38BrbtQgDXy3\nSNwsNiaNv6N5WeYbynSnLYQQFkJJWwghLISSthBCWAib3e764SwuBbDZhjaAEEL8RLHb7TbHNd1p\nCyGEhVDSFkIIC6GkLYQQFkJJWwghLISSthBCWAglbSGEsBBK2kIIYSGUtIUQwkIM+YFRl966GPSE\njHTyRDbjNI3c0mLyeAbh1IdVLz5nGvtfa36kNa94nEje3VxAnrM5eGBOe2YJeX6/4bem8R+6G0+6\nOXqWp9IYIXig1vAunuLsHoGHB7396p2msYtW8xTnfId/0UdqeULQW7k47cdnmD/oU++av++fruS1\n4wF4IFNGBk+4H9iPk2ECExaT5+KFa03jP/nCw6A707zJU7Id34zifeXkyfZx+Lwyj5nG/t11PLn7\nkefw4KIgOx9O9fdsPAVsQi1PXZrxm2dM409bfBHokPARoP/8yIv0mHoDDxIrWsvX6e2PzzeNvfr1\nj0AfOEb7Qoy2Qjw8a9KUZPIEB0SBvu2Je0xjb/jsa1p78O5nQM9cdiV5Xn0Fv0t3Xn0LedZ+9b1p\n/D/8+TWMNes88sQ5TARqtHeS5+gR8+lIutMWQggLoaQthBAWQklbCCEshJK2EEJYiCFvRCacfy3o\ni+/lqR1lFdh4HJXFDZ+koFjQq7ifQrT68hSY9Ho8dLDUczR5Kg5uAb3aY795sEE4aDuFsfz5+ZSW\ndoEutFWSZ1Sl6x9TThM/50PN2GAt8p1LnozAINCnbI4NKPNGpNss/oynuJWBvqLvEvJ8FH0adFJg\ng2mswWiYGg/6RNXPyBOe6AM6YsSH5In6BJtCNeRg9q4tpLXi5Q+B9rjoMHlCdlWBLmge50Q0ZuFY\nvJ4/2IbfpXtXPECP2f0JTnhKvXjiOcWuqsApMPmb8sjjMw6bk2MieIJR3ARuwprR2s4NfI8mvH4y\nFqWRp6MBr8vms6XkcYZd2/Fa6WnuIc8lC1JAp6UmkMctmt8P8rj43IQQQvwfoqQthBAWQklbCCEs\nxJDXtH/89B+40DCNPHtrsf7aWdhOnlHnmf+435G5wVxX8ovBTR11m7j2m9eJm3IiDlWQh7fkMJO6\n4kAHNPOk5a4grJSOreINL24h/DrMKK87SmuJxVhDCwjl15Wf9EfQ0/zwEsl1InbsWZ7yfqyoFXRJ\nCterbdE4/bykNXqQv/6DaXzfkVhDjm3nWP5z6kF7l19BnmkpvaA3ZOeYxk735Jp2byPWdr028aaT\nvkLcPNZ/jvX8xdcsBx3q/2/QKx7fSI+5Z8XfQD/1ixvOKfarr+HGp7S0MeT51dXYyxh1wXjyVBaX\nuBy7vqyL1iKnYvzYev5uHS+sBd3lEUceZ77tJft340L+HvJ0t+LE+NkPLSDPyGg/01i60xZCCAuh\npC2EEBZCSVsIISyEkrYQQliIIW9EFhzG/wuJV3FTLb4Pf1De0cxNmPbO4y7H7nWz01pMHZ6Yt+az\nzeT5LvMg6LQRg2x0qOIlRyYnNIPuGTmDPCOqsDnpHrqXPLnd/rRmRlcxNwOzu7Ex41nrTp6O+dh0\nmd4znTymsYNCaW1cajLo4/z0DC/c52Akj0h1ObZhGMaG1d+C9g0KIU9EGW6iqGjjJpXHTIdNQl+Y\nx/ZJ5b/T0+4B2s2Xr8uAONwc4l3L76EzHMnfCXrhDQ+CDjNw85RhGMaL63Ez2fOJZ84p9tSZ2Ohe\ndte95Jm1GPPByS38XX/9g7+6HLulr57Wzo/Dz73N9zR56h32ssUOsgHOGZZkLAG9but28nRtWQV6\n+KwI8kxLDMOFaP4O6E5bCCEshJK2EEJYCCVtIYSwEENe077uN1gTfeymy/hJlGN9cU/uLvKE9+OP\n8PcaPKnCkY4CroO/fOw70GuzeEpH2AD+L1t6I9e0f3yaa1aOeHphje/yGN7MUmOMBB2cdB15LmrB\nA4a2rTYNbfT38AE6pf34ftyYMIk8BV1YZ2sapNZrxhff+9DatRMng67vayVPYSluOgmd5UkeZ4hL\nxb/j482HcNlPJoH26+LNSHUHXN/gMs47hdY89mPNuCeZ+zqeTXggmn95HXmc4cdTHaDtIViIT4/l\nzSyLZ+P7U511bocm/em1p0DHhkWR55v3cELPiyt/R56c1nPYWDTAh0x5Dcf6dEtxG3lqBgJBh6Ul\nkccZks7DTXtzxvDhVL2r8TPdvIpzyNRrcPJQ+FSOpTttIYSwEEraQghhIZS0hRDCQihpCyGEhbDZ\n7fxD//8ajt4sAAAF2klEQVRoAJttaAMIIcRPFLvdTkdC6k5bCCEshJK2EEJYCCVtIYSwEEraQghh\nIZS0hRDCQihpCyGEhVDSFkIIC6GkLYQQFmLIT/lb8hc8Wc7mvo08QZlXg65b/C15vtwbjgtvXWsa\ne8eL19NaUSmewlYbyCfJzQroBN3VeiF5Ln5hCa058u2Ce0CHtXuRpy4FY6XUeZCnMLgL9KJP3jON\n/ezt6bzYj/ucent4SkdjK8b3ccPJOi99udU09oe33UZrqQvuBH2qgV/D0Y7Z+Bg3nqxz38O3mMaP\nWorHINYUdZJnejx+FoFufP8SGI2vfc0bvzSNbf9iP61l5+8BXV3Fp/wV9OBrzWvNJs/7n35mGv+5\nvz4JOusL/L6Fe9XQY5pacYzQvDkLyHPPyhdMY//xjcdBJxb6kqc+uRe0tw/tHTE6S/B0wIdf+JVp\n7P8mdKcthBAWQklbCCEshJK2EEJYiCGvaY+1JYPu6U4gz8Ff+YE+coBHdU+MxjrXESdij0vhmvaY\nGJzM4h/WQp62IJxC0dZ0DpM0DMPIKMSaqG9HMXkqO3FyRm8j19gnRza6HDvZk+vVoaPiQLv395Fn\nw3s43aPE5voElYHxfEZY2tX4vr93w1ny5AzLBD3trmdcjm0YhjHfhp/p/oER5GlqaQbdkMDTbfrb\nm2nNjJOp/rRW545TVcrj+XFbvs0H7VUSyCYnOPgcTjkqbMIR90FROBnFMAzj1l8OB506fzn/YSdq\n2kkG/p3DcTwhfVf+MdBvjL6cPMNGe5vG+m9Gd9pCCGEhlLSFEMJCKGkLIYSFUNIWQggLMeSNyIbx\n2FRoPhFOnu71uaC97FHk6R+32+XY4ZeMpbW2Styocjqmlzy9h7Bx1LCFG4jOcKhjFOhpTX7k6Q3B\nZtfwgQryuJc0uRz7y6p+WgvYg+9hfnU7eWZdhxsrYqLngP78qQOmscc+PJvWbhr7EOhtA7Xkuf3J\nm0DPSzm3ZtyZC6aATjIiyNOWjJ9FYD03RusKjtOaGbaqTF6rx40zCaXc9Mw6gQ3EkfZUl2MbhmHE\nBZ0GPWbcz0Bf89yv6THJ52HzNMwt6Jxipwzgdz107s3k+fjDP4GeuYPf47fv/ec5xf9vQXfaQghh\nIZS0hRDCQihpCyGEhRjymnbUx3hYT1Qcb+io6sea2kXzuR47eTtukHjMidgPvLmH1lr88W8XnKoi\nT1s31vTsJ486EY2JCsTX2tzFb7dfJx5c1FLP9fzS2Em4UJVlGruhcTytbavH+DHJfKiUR9w80OE+\nXPc249fXPUlrZQl4SNLax3aS57xhuOvkhuWvuhzbMAyjqQ7fw4xJieQ52oh1Zs+Sr8hji+Pasxk7\nDwxyINoNV4Au6OEeieORVq1+vDHFGfwT8fOLm4WfcUss9o8MwzDKuieCXlfYRh5nONJaCPquiYvJ\n887Lfwd98803kmfL5/xZiP9Fd9pCCGEhlLSFEMJCKGkLIYSFUNIWQggLMeSNyJIWbLqMSplDnslT\nsBmY3sg/7s8a4frJX9/k8ZSOvm6cptGcx6fhNY/AE9fGRp/bJo9v/LEZOKKETwuMacHXXp3ADSj3\nk9Eux+6+7FJae+q634Hu9OVNJ6//6XnQZ92cOU8Rye4NpbX5lyWBnjCNYx/ZhSfStQR0uxzbMAxj\nQtgJ0AMtPAFneqwP6KOd/Jwj8lz/euz1LKe1uUWtoOuauDGaHpsH+mA1T31xhogF2NTPGI4nVkZ6\nXUaPcffFDS7ePXHkcYbtB/G7Pvo9/iHARbfOBP2rp/9Ins58hx8r7Dinp/OTRXfaQghhIZS0hRDC\nQihpCyGEhbDZ7TxlRAghxP9PdKcthBAWQklbCCEshJK2EEJYCCVtIYSwEEraQghhIZS0hRDCQihp\nCyGEhVDSFkIIC6GkLYQQFkJJWwghLISSthBCWAglbSGEsBBK2kIIYSGUtIUQwkIoaQshhIVQ0hZC\nCAuhpC2EEBZCSVsIISyEkrYQQlgIJW0hhLAQ/wMztUhCcU05dwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6af0ad6278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How do the filters in the first layer look like?\n",
    "\n",
    "for param in network.params:\n",
    "    if param.name.endswith('weights'):\n",
    "        plot_mat(param.get_value(), cmap='gray')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iii = network.predict.maker.inputs[0]\n",
    "X = iii.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'after_C1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-664c4f416549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m middle_layers_computer = theano.function([X], [\n\u001b[0;32m      4\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mafter_C1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mafter_P1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mafter_C2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'after_C1' is not defined"
     ]
    }
   ],
   "source": [
    "# build a function that shows how the network processes an image\n",
    "\n",
    "middle_layers_computer = theano.function([X], [\n",
    "        X,\n",
    "        after_C1,\n",
    "        after_P1,\n",
    "        after_C2,\n",
    "        after_P2\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_num=4\n",
    "\n",
    "middle_layers = middle_layers_computer(X_test_value[img_num:img_num+1])\n",
    "\n",
    "for ml, name in zip(middle_layers, ['X', 'C1', 'P1', 'C2', 'P2']):\n",
    "    plot_mat(ml.transpose(1,0,2,3), cmap='gray')\n",
    "    title(name)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
