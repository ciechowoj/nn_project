{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import theano\n",
    "import theano.tensor.signal.downsample\n",
    "from common.plotting import plot_mat\n",
    "\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing ('features', 'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (25, 3, 32, 32) containing float32\n",
      " - an array of size (25, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}))\n",
    "\n",
    "cifar_train = CIFAR10((\"train\",), subset=slice(None,40000))\n",
    "cifar_train_stream = DataStream.default_stream(\n",
    "    cifar_train,\n",
    "    iteration_scheme = ShuffledScheme(cifar_train.num_examples, 25))\n",
    "                                               \n",
    "cifar_validation = CIFAR10((\"train\",), subset=slice(40000, None))\n",
    "cifar_validation_stream = DataStream.default_stream(\n",
    "    cifar_validation, \n",
    "    iteration_scheme = SequentialScheme(cifar_validation.num_examples, 100))\n",
    "\n",
    "cifar_test = CIFAR10((\"test\",))\n",
    "cifar_test_stream = DataStream.default_stream(\n",
    "    cifar_test, \n",
    "    iteration_scheme = SequentialScheme(cifar_test.num_examples, 100))\n",
    "\n",
    "print(\"The streams return batches containing %s\" % (cifar_train_stream.sources,))\n",
    "\n",
    "print(\"Each trainin batch consits of a tuple containing:\")\n",
    "for element in next(cifar_train_stream.get_epoch_iterator()):\n",
    "    print(\" - an array of size %s containing %s\" % (element.shape, element.dtype))\n",
    "    \n",
    "print(\"Validation/test batches consits of tuples containing:\")\n",
    "for element in next(cifar_test_stream.get_epoch_iterator()):\n",
    "    print(\" - an array of size %s containing %s\" % (element.shape, element.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X type: float32\n",
      "X shape: (4, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# A theano variable is an entry to the cmputational graph\n",
    "# We will need to provide its value during function call\n",
    "# X is batch_size x num_channels x img_rows x img_columns\n",
    "X = theano.tensor.tensor4('X', dtype='float32')\n",
    "\n",
    "# Y is 1D, it lists the targets for all examples\n",
    "Y = theano.tensor.matrix('Y', dtype='uint8')\n",
    "\n",
    "# this list will hold all parameters of the network\n",
    "model_parameters = []\n",
    "\n",
    "#The first convolutional layer\n",
    "#The shape is: num_out_filters x num_in_filters x filter_height x filter_width\n",
    "num_filters_1 = 10 #we will apply that many convolution filters in the first layer\n",
    "CW1 = theano.shared(np.zeros((num_filters_1, 3, 5, 5), dtype = 'float32'),\n",
    "                   name='CW1')\n",
    "#please note - this is somewhat non-standard\n",
    "CW1.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "CB1 = theano.shared(np.zeros((num_filters_1,), dtype='float32'),\n",
    "                    name='CB1')\n",
    "\n",
    "CB1.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW1, CB1]\n",
    "\n",
    "after_C1 = theano.tensor.maximum(\n",
    "    0.0,\n",
    "    theano.tensor.nnet.conv2d(X, CW1) + CB1.dimshuffle('x',0,'x','x')\n",
    "    )\n",
    "\n",
    "\n",
    "after_P1 = theano.tensor.signal.downsample.max_pool_2d(after_C1, (2,2), ignore_border=True)\n",
    "\n",
    "num_filters_2 = 25 #we will compute ten convolution filters in the first layer\n",
    "CW2 = theano.shared(np.zeros((num_filters_2,num_filters_1,5,5), dtype='float32'),\n",
    "                   name='CW2')\n",
    "\n",
    "CW2.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "CB2 = theano.shared(np.zeros((num_filters_2,), dtype='float32'),\n",
    "                    name='CB2')\n",
    "\n",
    "CB2.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW2, CB2]\n",
    "\n",
    "after_C2 = theano.tensor.maximum(\n",
    "    0.0,\n",
    "    theano.tensor.nnet.conv2d(after_P1, CW2) + CB2.dimshuffle('x',0,'x','x')\n",
    "    )\n",
    "\n",
    "after_P2 = theano.tensor.signal.downsample.max_pool_2d(after_C2, (2,2), ignore_border=True)\n",
    "\n",
    "#Fully connected layers - we just flatten all filter maps\n",
    "num_fw3_hidden=500\n",
    "FW3 = theano.shared(np.zeros((num_filters_2 * 5 * 5, num_fw3_hidden), dtype='float32'),\n",
    "                   name='FW3')\n",
    "FW3.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "FB3 = theano.shared(np.zeros((num_fw3_hidden,), dtype='float32'),\n",
    "                    name='FB3')\n",
    "FB3.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW3, FB3]\n",
    "\n",
    "after_F3 = theano.tensor.maximum(0.0, \n",
    "                                 theano.tensor.dot(after_P2.flatten(2), FW3) + FB3.dimshuffle('x',0))\n",
    "# print \"after_F3 shape: %s\" % (after_F3.tag.test_value.shape,)\n",
    "\n",
    "\n",
    "num_fw4_hidden=10\n",
    "FW4 = theano.shared(np.zeros((num_fw3_hidden, num_fw4_hidden), dtype='float32'),\n",
    "                   name='FW4')\n",
    "FW4.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "FB4 = theano.shared(np.zeros((num_fw4_hidden,), dtype='float32'),\n",
    "                    name='FB4')\n",
    "FB4.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW4, FB4]\n",
    "\n",
    "after_F4 = theano.tensor.dot(after_F3, FW4) + FB4.dimshuffle('x',0)\n",
    "# print \"after_F4 shape: %s\" % (after_F4.tag.test_value.shape,)\n",
    "\n",
    "log_probs = theano.tensor.nnet.softmax(after_F4)\n",
    "\n",
    "predictions = theano.tensor.argmax(log_probs, axis=1)\n",
    "\n",
    "error_rate = theano.tensor.neq(predictions,Y.ravel()).mean()\n",
    "nll = - theano.tensor.log(log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()\n",
    "\n",
    "weight_decay = 0.0\n",
    "for p in model_parameters:\n",
    "    if p.name[1]=='W':\n",
    "        weight_decay = weight_decay + 1e-3 * (p**2).sum()\n",
    "\n",
    "cost = nll + weight_decay\n",
    "\n",
    "#At this point stop computing test values\n",
    "theano.config.compute_test_value = 'off' # Enable the computation of test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# We have built a computation graph for computing the error_rate, predictions and cost\n",
    "#\n",
    "\n",
    "# svgdotprint(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The updates will update our shared values\n",
    "updates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrate = theano.tensor.scalar('lrate',dtype='float32')\n",
    "momentum = theano.tensor.scalar('momentum',dtype='float32')\n",
    "\n",
    "# Theano will compute the gradients for us\n",
    "gradients = theano.grad(cost, model_parameters)\n",
    "\n",
    "#initialize storage for momentum\n",
    "velocities = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in model_parameters]\n",
    "\n",
    "for p,g,v in zip(model_parameters, gradients, velocities):\n",
    "    v_new = momentum * v - lrate * g\n",
    "    p_new = p + v_new\n",
    "    updates += [(v,v_new), (p, p_new)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(V_CW1, Elemwise{sub,no_inplace}.0),\n",
       " (CW1, Elemwise{add,no_inplace}.0),\n",
       " (V_CB1, Elemwise{sub,no_inplace}.0),\n",
       " (CB1, Elemwise{add,no_inplace}.0),\n",
       " (V_CW2, Elemwise{sub,no_inplace}.0),\n",
       " (CW2, Elemwise{add,no_inplace}.0),\n",
       " (V_CB2, Elemwise{sub,no_inplace}.0),\n",
       " (CB2, Elemwise{add,no_inplace}.0),\n",
       " (V_FW3, Elemwise{sub,no_inplace}.0),\n",
       " (FW3, Elemwise{add,no_inplace}.0),\n",
       " (V_FB3, Elemwise{sub,no_inplace}.0),\n",
       " (FB3, Elemwise{add,no_inplace}.0),\n",
       " (V_FW4, Elemwise{sub,no_inplace}.0),\n",
       " (FW4, Elemwise{add,no_inplace}.0),\n",
       " (V_FB4, Elemwise{sub,no_inplace}.0),\n",
       " (FB4, Elemwise{add,no_inplace}.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile theano functions\n",
    "\n",
    "#each call to train step will make one SGD step\n",
    "train_step = theano.function([X,Y,lrate,momentum],[cost, error_rate, nll, weight_decay],updates=updates, allow_input_downcast=True)\n",
    "#each call to predict will return predictions on a batch of data\n",
    "predict = theano.function([X], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(stream):\n",
    "    errs = 0.0\n",
    "    num_samples = 0.0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        errs += (predict(X)!=Y.ravel()).sum()\n",
    "        num_samples += Y.shape[0]\n",
    "    return errs/num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utilities to save values of parameters and to load them\n",
    "\n",
    "def init_parameters():\n",
    "    rng = np.random.RandomState(1234)\n",
    "    for p in model_parameters:\n",
    "        p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "\n",
    "def snapshot_parameters():\n",
    "    return [p.get_value(borrow=False) for p in model_parameters]\n",
    "\n",
    "def load_parameters(snapshot):\n",
    "    for p, s in zip(model_parameters, snapshot):\n",
    "        p.set_value(s, borrow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init training\n",
    "\n",
    "i=0\n",
    "e=0\n",
    "\n",
    "init_parameters()\n",
    "for v in velocities:\n",
    "    v.set_value(np.zeros_like(v.get_value()))\n",
    "\n",
    "best_valid_error_rate = np.inf\n",
    "best_params = snapshot_parameters()\n",
    "best_params_epoch = 0\n",
    "\n",
    "train_erros = []\n",
    "train_loss = []\n",
    "train_nll = []\n",
    "validation_errors = []\n",
    "\n",
    "number_of_epochs = 3\n",
    "patience_expansion = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At minibatch 100, batch loss 2.655634, batch nll 1.852118, batch error rate 72.000000%\n",
      "At minibatch 200, batch loss 2.841293, batch nll 2.048522, batch error rate 76.000000%\n",
      "At minibatch 300, batch loss 2.672361, batch nll 1.889672, batch error rate 64.000000%\n",
      "At minibatch 400, batch loss 2.561451, batch nll 1.788823, batch error rate 60.000000%\n",
      "At minibatch 500, batch loss 2.365767, batch nll 1.603615, batch error rate 60.000000%\n",
      "At minibatch 600, batch loss 2.258395, batch nll 1.506265, batch error rate 60.000000%\n",
      "At minibatch 700, batch loss 2.086475, batch nll 1.344160, batch error rate 56.000000%\n",
      "At minibatch 800, batch loss 2.224329, batch nll 1.491740, batch error rate 56.000000%\n",
      "At minibatch 900, batch loss 2.339763, batch nll 1.616507, batch error rate 64.000000%\n",
      "At minibatch 1000, batch loss 2.428953, batch nll 1.715350, batch error rate 76.000000%\n",
      "At minibatch 1100, batch loss 2.191958, batch nll 1.487247, batch error rate 60.000000%\n",
      "At minibatch 1200, batch loss 2.157705, batch nll 1.462197, batch error rate 64.000000%\n",
      "At minibatch 1300, batch loss 1.646881, batch nll 0.960179, batch error rate 28.000000%\n",
      "At minibatch 1400, batch loss 2.251100, batch nll 1.572945, batch error rate 60.000000%\n",
      "At minibatch 1500, batch loss 1.750050, batch nll 1.080234, batch error rate 36.000000%\n",
      "At minibatch 1600, batch loss 2.052834, batch nll 1.391889, batch error rate 60.000000%\n",
      "After epoch 1: valid_err_rate: 52.420000% currently going to do 3 epochs\n",
      "After epoch 1: averaged train_err_rate: 57.790000% averaged train nll: 1.597496 averaged train loss: 2.331834\n",
      "At minibatch 1700, batch loss 1.816236, batch nll 1.163072, batch error rate 36.000000%\n",
      "At minibatch 1800, batch loss 1.857771, batch nll 1.212304, batch error rate 56.000000%\n",
      "At minibatch 1900, batch loss 1.555761, batch nll 0.917783, batch error rate 32.000000%\n",
      "At minibatch 2000, batch loss 1.703630, batch nll 1.073679, batch error rate 32.000000%\n",
      "At minibatch 2100, batch loss 1.935468, batch nll 1.312684, batch error rate 60.000000%\n",
      "At minibatch 2200, batch loss 1.970726, batch nll 1.354484, batch error rate 48.000000%\n",
      "At minibatch 2300, batch loss 1.986116, batch nll 1.376463, batch error rate 48.000000%\n",
      "At minibatch 2400, batch loss 2.085747, batch nll 1.482188, batch error rate 52.000000%\n",
      "At minibatch 2500, batch loss 1.901321, batch nll 1.303957, batch error rate 44.000000%\n",
      "At minibatch 2600, batch loss 1.914569, batch nll 1.322944, batch error rate 48.000000%\n",
      "At minibatch 2700, batch loss 1.877239, batch nll 1.291165, batch error rate 56.000000%\n",
      "At minibatch 2800, batch loss 1.383272, batch nll 0.802480, batch error rate 20.000000%\n",
      "At minibatch 2900, batch loss 1.812340, batch nll 1.236239, batch error rate 52.000000%\n",
      "At minibatch 3000, batch loss 1.446182, batch nll 0.875058, batch error rate 36.000000%\n",
      "At minibatch 3100, batch loss 2.246412, batch nll 1.679330, batch error rate 64.000000%\n",
      "At minibatch 3200, batch loss 2.094814, batch nll 1.532096, batch error rate 44.000000%\n",
      "After epoch 2: valid_err_rate: 42.500000% currently going to do 4 epochs\n",
      "After epoch 2: averaged train_err_rate: 44.512500% averaged train nll: 1.251672 averaged train loss: 1.857918\n",
      "At minibatch 3300, batch loss 1.649504, batch nll 1.090526, batch error rate 48.000000%\n",
      "At minibatch 3400, batch loss 1.519522, batch nll 0.963928, batch error rate 36.000000%\n",
      "At minibatch 3500, batch loss 1.865963, batch nll 1.313772, batch error rate 36.000000%\n",
      "At minibatch 3600, batch loss 1.510213, batch nll 0.961350, batch error rate 24.000000%\n",
      "At minibatch 3700, batch loss 1.543923, batch nll 0.998436, batch error rate 32.000000%\n",
      "At minibatch 3800, batch loss 1.950853, batch nll 1.408479, batch error rate 52.000000%\n",
      "At minibatch 3900, batch loss 1.796979, batch nll 1.257723, batch error rate 48.000000%\n",
      "At minibatch 4000, batch loss 2.034187, batch nll 1.497938, batch error rate 44.000000%\n",
      "At minibatch 4100, batch loss 1.967411, batch nll 1.433938, batch error rate 44.000000%\n",
      "At minibatch 4200, batch loss 1.549790, batch nll 1.019226, batch error rate 36.000000%\n",
      "At minibatch 4300, batch loss 1.927236, batch nll 1.399511, batch error rate 40.000000%\n",
      "At minibatch 4400, batch loss 1.464782, batch nll 0.939656, batch error rate 28.000000%\n",
      "At minibatch 4500, batch loss 1.568833, batch nll 1.046578, batch error rate 36.000000%\n",
      "At minibatch 4600, batch loss 1.733794, batch nll 1.214146, batch error rate 44.000000%\n",
      "At minibatch 4700, batch loss 1.469796, batch nll 0.952690, batch error rate 28.000000%\n",
      "At minibatch 4800, batch loss 1.429645, batch nll 0.914780, batch error rate 36.000000%\n",
      "After epoch 3: valid_err_rate: 39.230000% currently going to do 5 epochs\n",
      "After epoch 3: averaged train_err_rate: 37.767500% averaged train nll: 1.076127 averaged train loss: 1.613230\n",
      "At minibatch 4900, batch loss 1.543402, batch nll 1.030313, batch error rate 28.000000%\n",
      "At minibatch 5000, batch loss 1.391249, batch nll 0.880068, batch error rate 28.000000%\n",
      "At minibatch 5100, batch loss 1.575713, batch nll 1.066465, batch error rate 36.000000%\n",
      "At minibatch 5200, batch loss 1.959273, batch nll 1.452008, batch error rate 56.000000%\n",
      "At minibatch 5300, batch loss 1.360074, batch nll 0.854715, batch error rate 32.000000%\n",
      "At minibatch 5400, batch loss 1.449177, batch nll 0.945845, batch error rate 28.000000%\n",
      "At minibatch 5500, batch loss 1.560779, batch nll 1.059238, batch error rate 36.000000%\n",
      "At minibatch 5600, batch loss 1.647617, batch nll 1.147715, batch error rate 32.000000%\n",
      "At minibatch 5700, batch loss 1.237825, batch nll 0.739862, batch error rate 24.000000%\n",
      "At minibatch 5800, batch loss 1.841241, batch nll 1.344847, batch error rate 52.000000%\n",
      "At minibatch 5900, batch loss 1.878654, batch nll 1.383850, batch error rate 56.000000%\n",
      "At minibatch 6000, batch loss 1.450058, batch nll 0.957053, batch error rate 32.000000%\n",
      "At minibatch 6100, batch loss 1.069879, batch nll 0.578556, batch error rate 24.000000%\n",
      "At minibatch 6200, batch loss 1.297695, batch nll 0.807954, batch error rate 28.000000%\n",
      "At minibatch 6300, batch loss 1.377617, batch nll 0.889457, batch error rate 36.000000%\n",
      "At minibatch 6400, batch loss 1.493128, batch nll 1.006400, batch error rate 48.000000%\n",
      "After epoch 4: valid_err_rate: 36.220000% currently going to do 7 epochs\n",
      "After epoch 4: averaged train_err_rate: 34.027500% averaged train nll: 0.969722 averaged train loss: 1.469905\n",
      "At minibatch 6500, batch loss 1.421214, batch nll 0.935565, batch error rate 24.000000%\n",
      "At minibatch 6600, batch loss 1.310829, batch nll 0.826598, batch error rate 32.000000%\n",
      "At minibatch 6700, batch loss 1.289006, batch nll 0.805980, batch error rate 24.000000%\n",
      "At minibatch 6800, batch loss 1.288152, batch nll 0.806716, batch error rate 24.000000%\n",
      "At minibatch 6900, batch loss 1.352225, batch nll 0.871973, batch error rate 24.000000%\n",
      "At minibatch 7000, batch loss 1.726955, batch nll 1.247753, batch error rate 40.000000%\n",
      "At minibatch 7100, batch loss 1.400129, batch nll 0.922034, batch error rate 28.000000%\n",
      "At minibatch 7200, batch loss 1.436978, batch nll 0.960188, batch error rate 44.000000%\n",
      "At minibatch 7300, batch loss 1.085922, batch nll 0.610260, batch error rate 20.000000%\n",
      "At minibatch 7400, batch loss 1.288695, batch nll 0.813999, batch error rate 28.000000%\n",
      "At minibatch 7500, batch loss 1.281350, batch nll 0.808086, batch error rate 32.000000%\n",
      "At minibatch 7600, batch loss 1.155627, batch nll 0.683436, batch error rate 24.000000%\n",
      "At minibatch 7700, batch loss 1.274015, batch nll 0.803211, batch error rate 28.000000%\n",
      "At minibatch 7800, batch loss 1.448361, batch nll 0.978596, batch error rate 36.000000%\n",
      "At minibatch 7900, batch loss 0.949812, batch nll 0.481141, batch error rate 12.000000%\n",
      "At minibatch 8000, batch loss 1.216138, batch nll 0.748531, batch error rate 24.000000%\n",
      "After epoch 5: valid_err_rate: 35.640000% currently going to do 8 epochs\n",
      "After epoch 5: averaged train_err_rate: 30.920000% averaged train nll: 0.890237 averaged train loss: 1.367162\n",
      "At minibatch 8100, batch loss 0.994032, batch nll 0.527308, batch error rate 12.000000%\n",
      "At minibatch 8200, batch loss 1.696173, batch nll 1.230391, batch error rate 44.000000%\n",
      "At minibatch 8300, batch loss 1.810900, batch nll 1.345856, batch error rate 40.000000%\n",
      "At minibatch 8400, batch loss 1.228432, batch nll 0.764254, batch error rate 24.000000%\n",
      "At minibatch 8500, batch loss 1.445252, batch nll 0.981860, batch error rate 36.000000%\n",
      "At minibatch 8600, batch loss 1.236752, batch nll 0.774188, batch error rate 28.000000%\n",
      "At minibatch 8700, batch loss 1.497063, batch nll 1.035429, batch error rate 24.000000%\n",
      "At minibatch 8800, batch loss 1.122178, batch nll 0.661474, batch error rate 20.000000%\n",
      "At minibatch 8900, batch loss 1.404194, batch nll 0.944475, batch error rate 32.000000%\n",
      "At minibatch 9000, batch loss 1.306729, batch nll 0.847829, batch error rate 36.000000%\n",
      "At minibatch 9100, batch loss 1.333605, batch nll 0.875645, batch error rate 36.000000%\n",
      "At minibatch 9200, batch loss 1.192756, batch nll 0.735516, batch error rate 24.000000%\n",
      "At minibatch 9300, batch loss 1.227478, batch nll 0.771004, batch error rate 24.000000%\n",
      "At minibatch 9400, batch loss 1.264788, batch nll 0.809147, batch error rate 36.000000%\n",
      "At minibatch 9500, batch loss 1.402734, batch nll 0.947937, batch error rate 40.000000%\n",
      "At minibatch 9600, batch loss 1.318718, batch nll 0.864664, batch error rate 28.000000%\n",
      "After epoch 6: valid_err_rate: 34.190000% currently going to do 10 epochs\n",
      "After epoch 6: averaged train_err_rate: 28.755000% averaged train nll: 0.830090 averaged train loss: 1.290811\n",
      "At minibatch 9700, batch loss 1.326033, batch nll 0.872436, batch error rate 32.000000%\n",
      "At minibatch 9800, batch loss 1.162340, batch nll 0.709458, batch error rate 24.000000%\n",
      "At minibatch 9900, batch loss 1.184391, batch nll 0.732172, batch error rate 28.000000%\n",
      "At minibatch 10000, batch loss 1.073336, batch nll 0.621561, batch error rate 16.000000%\n",
      "At minibatch 10100, batch loss 1.172852, batch nll 0.721733, batch error rate 20.000000%\n",
      "At minibatch 10200, batch loss 1.113700, batch nll 0.663216, batch error rate 16.000000%\n",
      "At minibatch 10300, batch loss 1.447800, batch nll 0.997920, batch error rate 36.000000%\n",
      "At minibatch 10400, batch loss 1.042704, batch nll 0.593485, batch error rate 16.000000%\n",
      "At minibatch 10500, batch loss 1.441964, batch nll 0.993671, batch error rate 32.000000%\n",
      "At minibatch 10600, batch loss 1.349828, batch nll 0.902105, batch error rate 24.000000%\n",
      "At minibatch 10700, batch loss 1.098662, batch nll 0.651729, batch error rate 20.000000%\n",
      "At minibatch 10800, batch loss 1.290210, batch nll 0.843916, batch error rate 36.000000%\n",
      "At minibatch 10900, batch loss 1.189287, batch nll 0.743452, batch error rate 36.000000%\n",
      "At minibatch 11000, batch loss 1.395472, batch nll 0.950284, batch error rate 32.000000%\n",
      "At minibatch 11100, batch loss 0.894563, batch nll 0.449989, batch error rate 12.000000%\n",
      "At minibatch 11200, batch loss 1.089444, batch nll 0.645525, batch error rate 20.000000%\n",
      "After epoch 7: valid_err_rate: 33.800000% currently going to do 11 epochs\n",
      "After epoch 7: averaged train_err_rate: 26.870000% averaged train nll: 0.777100 averaged train loss: 1.226162\n",
      "At minibatch 11300, batch loss 1.447667, batch nll 1.004080, batch error rate 28.000000%\n",
      "At minibatch 11400, batch loss 1.253303, batch nll 0.810217, batch error rate 24.000000%\n",
      "At minibatch 11500, batch loss 1.184663, batch nll 0.742050, batch error rate 20.000000%\n",
      "At minibatch 11600, batch loss 0.931673, batch nll 0.489671, batch error rate 16.000000%\n",
      "At minibatch 11700, batch loss 1.377340, batch nll 0.935814, batch error rate 32.000000%\n",
      "At minibatch 11800, batch loss 1.147775, batch nll 0.706761, batch error rate 28.000000%\n",
      "At minibatch 11900, batch loss 1.199692, batch nll 0.759162, batch error rate 16.000000%\n",
      "At minibatch 12000, batch loss 0.988179, batch nll 0.548074, batch error rate 28.000000%\n",
      "At minibatch 12100, batch loss 1.072364, batch nll 0.632873, batch error rate 24.000000%\n",
      "At minibatch 12200, batch loss 1.208496, batch nll 0.769498, batch error rate 24.000000%\n",
      "At minibatch 12300, batch loss 1.205475, batch nll 0.766955, batch error rate 24.000000%\n",
      "At minibatch 12400, batch loss 0.948900, batch nll 0.510808, batch error rate 24.000000%\n",
      "At minibatch 12500, batch loss 1.219385, batch nll 0.781731, batch error rate 24.000000%\n",
      "At minibatch 12600, batch loss 1.221661, batch nll 0.784550, batch error rate 32.000000%\n",
      "At minibatch 12700, batch loss 1.300099, batch nll 0.863455, batch error rate 28.000000%\n",
      "At minibatch 12800, batch loss 1.107009, batch nll 0.670811, batch error rate 20.000000%\n",
      "After epoch 8: valid_err_rate: 32.650000% currently going to do 13 epochs\n",
      "After epoch 8: averaged train_err_rate: 25.295000% averaged train nll: 0.732776 averaged train loss: 1.172842\n",
      "At minibatch 12900, batch loss 1.178657, batch nll 0.742825, batch error rate 32.000000%\n",
      "At minibatch 13000, batch loss 1.115933, batch nll 0.680317, batch error rate 20.000000%\n",
      "At minibatch 13100, batch loss 0.984662, batch nll 0.549427, batch error rate 16.000000%\n",
      "At minibatch 13200, batch loss 0.895432, batch nll 0.460603, batch error rate 16.000000%\n",
      "At minibatch 13300, batch loss 1.305416, batch nll 0.870923, batch error rate 32.000000%\n",
      "At minibatch 13400, batch loss 1.201653, batch nll 0.767558, batch error rate 44.000000%\n",
      "At minibatch 13500, batch loss 1.096000, batch nll 0.662257, batch error rate 20.000000%\n",
      "At minibatch 13600, batch loss 1.238555, batch nll 0.805185, batch error rate 28.000000%\n",
      "At minibatch 13700, batch loss 1.037925, batch nll 0.604955, batch error rate 16.000000%\n",
      "At minibatch 13800, batch loss 1.138173, batch nll 0.705601, batch error rate 28.000000%\n",
      "At minibatch 13900, batch loss 1.209434, batch nll 0.777308, batch error rate 16.000000%\n",
      "At minibatch 14000, batch loss 0.879780, batch nll 0.448156, batch error rate 16.000000%\n",
      "At minibatch 14100, batch loss 1.224718, batch nll 0.793500, batch error rate 24.000000%\n",
      "At minibatch 14200, batch loss 1.164242, batch nll 0.733474, batch error rate 28.000000%\n",
      "At minibatch 14300, batch loss 1.153509, batch nll 0.723139, batch error rate 20.000000%\n",
      "At minibatch 14400, batch loss 1.050033, batch nll 0.620014, batch error rate 16.000000%\n",
      "After epoch 9: valid_err_rate: 32.480000% currently going to do 14 epochs\n",
      "After epoch 9: averaged train_err_rate: 23.767500% averaged train nll: 0.691583 averaged train loss: 1.124830\n",
      "At minibatch 14500, batch loss 0.998898, batch nll 0.569118, batch error rate 20.000000%\n",
      "At minibatch 14600, batch loss 0.875463, batch nll 0.445969, batch error rate 16.000000%\n",
      "At minibatch 14700, batch loss 0.890101, batch nll 0.460855, batch error rate 16.000000%\n",
      "At minibatch 14800, batch loss 1.218519, batch nll 0.789569, batch error rate 20.000000%\n",
      "At minibatch 14900, batch loss 1.465576, batch nll 1.036908, batch error rate 44.000000%\n",
      "At minibatch 15000, batch loss 1.068757, batch nll 0.640436, batch error rate 36.000000%\n",
      "At minibatch 15100, batch loss 1.066748, batch nll 0.638615, batch error rate 20.000000%\n",
      "At minibatch 15200, batch loss 1.172393, batch nll 0.744645, batch error rate 24.000000%\n",
      "At minibatch 15300, batch loss 1.249035, batch nll 0.821572, batch error rate 36.000000%\n",
      "At minibatch 15400, batch loss 1.236951, batch nll 0.809810, batch error rate 24.000000%\n",
      "At minibatch 15500, batch loss 1.290878, batch nll 0.864004, batch error rate 28.000000%\n",
      "At minibatch 15600, batch loss 0.748860, batch nll 0.322364, batch error rate 12.000000%\n",
      "At minibatch 15700, batch loss 1.052625, batch nll 0.626500, batch error rate 24.000000%\n",
      "At minibatch 15800, batch loss 1.284694, batch nll 0.858927, batch error rate 24.000000%\n",
      "At minibatch 15900, batch loss 0.842094, batch nll 0.416665, batch error rate 20.000000%\n",
      "At minibatch 16000, batch loss 1.230052, batch nll 0.804975, batch error rate 32.000000%\n",
      "After epoch 10: valid_err_rate: 32.550000% currently going to do 14 epochs\n",
      "After epoch 10: averaged train_err_rate: 22.480000% averaged train nll: 0.657198 averaged train loss: 1.084897\n",
      "At minibatch 16100, batch loss 1.137191, batch nll 0.712259, batch error rate 28.000000%\n",
      "At minibatch 16200, batch loss 0.841427, batch nll 0.416652, batch error rate 8.000000%\n",
      "At minibatch 16300, batch loss 0.957630, batch nll 0.533046, batch error rate 20.000000%\n",
      "At minibatch 16400, batch loss 1.055944, batch nll 0.631514, batch error rate 24.000000%\n",
      "At minibatch 16500, batch loss 1.491254, batch nll 1.067109, batch error rate 36.000000%\n",
      "At minibatch 16600, batch loss 0.717900, batch nll 0.294033, batch error rate 12.000000%\n",
      "At minibatch 16700, batch loss 1.138739, batch nll 0.715125, batch error rate 28.000000%\n",
      "At minibatch 16800, batch loss 0.825699, batch nll 0.402341, batch error rate 16.000000%\n",
      "At minibatch 16900, batch loss 0.893994, batch nll 0.470900, batch error rate 20.000000%\n",
      "At minibatch 17000, batch loss 1.072171, batch nll 0.649359, batch error rate 20.000000%\n",
      "At minibatch 17100, batch loss 1.191350, batch nll 0.768791, batch error rate 20.000000%\n",
      "At minibatch 17200, batch loss 1.017809, batch nll 0.595538, batch error rate 20.000000%\n",
      "At minibatch 17300, batch loss 1.392904, batch nll 0.970914, batch error rate 36.000000%\n",
      "At minibatch 17400, batch loss 0.847355, batch nll 0.425616, batch error rate 20.000000%\n",
      "At minibatch 17500, batch loss 0.835666, batch nll 0.414167, batch error rate 8.000000%\n",
      "At minibatch 17600, batch loss 0.953765, batch nll 0.532507, batch error rate 20.000000%\n",
      "After epoch 11: valid_err_rate: 32.350000% currently going to do 17 epochs\n",
      "After epoch 11: averaged train_err_rate: 21.052500% averaged train nll: 0.621967 averaged train loss: 1.045276\n",
      "At minibatch 17700, batch loss 1.134125, batch nll 0.713045, batch error rate 28.000000%\n",
      "At minibatch 17800, batch loss 0.757507, batch nll 0.336595, batch error rate 16.000000%\n",
      "At minibatch 17900, batch loss 0.834720, batch nll 0.413998, batch error rate 8.000000%\n",
      "At minibatch 18000, batch loss 0.975859, batch nll 0.555278, batch error rate 12.000000%\n",
      "At minibatch 18100, batch loss 1.051308, batch nll 0.630916, batch error rate 28.000000%\n",
      "At minibatch 18200, batch loss 1.086779, batch nll 0.666585, batch error rate 20.000000%\n",
      "At minibatch 18300, batch loss 0.973309, batch nll 0.553266, batch error rate 12.000000%\n",
      "At minibatch 18400, batch loss 1.591574, batch nll 1.171693, batch error rate 40.000000%\n",
      "At minibatch 18500, batch loss 1.175777, batch nll 0.756103, batch error rate 24.000000%\n",
      "At minibatch 18600, batch loss 1.124029, batch nll 0.704483, batch error rate 24.000000%\n",
      "At minibatch 18700, batch loss 1.211718, batch nll 0.792346, batch error rate 32.000000%\n",
      "At minibatch 18800, batch loss 0.816243, batch nll 0.397162, batch error rate 8.000000%\n",
      "At minibatch 18900, batch loss 1.107092, batch nll 0.688278, batch error rate 28.000000%\n",
      "At minibatch 19000, batch loss 1.000081, batch nll 0.581486, batch error rate 24.000000%\n",
      "At minibatch 19100, batch loss 0.805070, batch nll 0.386724, batch error rate 12.000000%\n",
      "At minibatch 19200, batch loss 0.981229, batch nll 0.563146, batch error rate 20.000000%\n",
      "After epoch 12: valid_err_rate: 32.210000% currently going to do 19 epochs\n",
      "After epoch 12: averaged train_err_rate: 19.877500% averaged train nll: 0.590553 averaged train loss: 1.010355\n",
      "At minibatch 19300, batch loss 1.105658, batch nll 0.687687, batch error rate 24.000000%\n",
      "At minibatch 19400, batch loss 1.134618, batch nll 0.716744, batch error rate 24.000000%\n",
      "At minibatch 19500, batch loss 1.154385, batch nll 0.736590, batch error rate 20.000000%\n",
      "At minibatch 19600, batch loss 0.789846, batch nll 0.372205, batch error rate 16.000000%\n",
      "At minibatch 19700, batch loss 1.018446, batch nll 0.600949, batch error rate 20.000000%\n",
      "At minibatch 19800, batch loss 1.218290, batch nll 0.800934, batch error rate 20.000000%\n",
      "At minibatch 19900, batch loss 0.905746, batch nll 0.488584, batch error rate 16.000000%\n",
      "At minibatch 20000, batch loss 1.098601, batch nll 0.681637, batch error rate 36.000000%\n",
      "At minibatch 20100, batch loss 1.086086, batch nll 0.669280, batch error rate 12.000000%\n",
      "At minibatch 20200, batch loss 1.152597, batch nll 0.735930, batch error rate 20.000000%\n",
      "At minibatch 20300, batch loss 1.454984, batch nll 1.038430, batch error rate 28.000000%\n",
      "At minibatch 20400, batch loss 1.176774, batch nll 0.760433, batch error rate 32.000000%\n",
      "At minibatch 20500, batch loss 1.004785, batch nll 0.588697, batch error rate 24.000000%\n",
      "At minibatch 20600, batch loss 1.004817, batch nll 0.588931, batch error rate 20.000000%\n",
      "At minibatch 20700, batch loss 0.836728, batch nll 0.421020, batch error rate 8.000000%\n",
      "At minibatch 20800, batch loss 0.889829, batch nll 0.474313, batch error rate 16.000000%\n",
      "After epoch 13: valid_err_rate: 31.910000% currently going to do 20 epochs\n",
      "After epoch 13: averaged train_err_rate: 18.735000% averaged train nll: 0.562711 averaged train loss: 0.979654\n",
      "At minibatch 20900, batch loss 1.106687, batch nll 0.691200, batch error rate 28.000000%\n",
      "At minibatch 21000, batch loss 1.011649, batch nll 0.596264, batch error rate 20.000000%\n",
      "At minibatch 21100, batch loss 0.890921, batch nll 0.475679, batch error rate 12.000000%\n",
      "At minibatch 21200, batch loss 0.974550, batch nll 0.559402, batch error rate 20.000000%\n",
      "At minibatch 21300, batch loss 0.854551, batch nll 0.439485, batch error rate 16.000000%\n",
      "At minibatch 21400, batch loss 0.887609, batch nll 0.472682, batch error rate 16.000000%\n",
      "At minibatch 21500, batch loss 0.877161, batch nll 0.462411, batch error rate 16.000000%\n",
      "At minibatch 21600, batch loss 0.955593, batch nll 0.540981, batch error rate 24.000000%\n",
      "At minibatch 21700, batch loss 1.115943, batch nll 0.701523, batch error rate 28.000000%\n",
      "At minibatch 21800, batch loss 0.980201, batch nll 0.565898, batch error rate 20.000000%\n",
      "At minibatch 21900, batch loss 0.839644, batch nll 0.425464, batch error rate 16.000000%\n",
      "At minibatch 22000, batch loss 0.931431, batch nll 0.517435, batch error rate 8.000000%\n",
      "At minibatch 22100, batch loss 0.688007, batch nll 0.274169, batch error rate 8.000000%\n",
      "At minibatch 22200, batch loss 1.095633, batch nll 0.681934, batch error rate 28.000000%\n",
      "At minibatch 22300, batch loss 0.852656, batch nll 0.439115, batch error rate 20.000000%\n",
      "At minibatch 22400, batch loss 1.203148, batch nll 0.789730, batch error rate 28.000000%\n",
      "After epoch 14: valid_err_rate: 31.950000% currently going to do 20 epochs\n",
      "After epoch 14: averaged train_err_rate: 17.982500% averaged train nll: 0.535462 averaged train loss: 0.950029\n",
      "At minibatch 22500, batch loss 0.870437, batch nll 0.457123, batch error rate 24.000000%\n",
      "At minibatch 22600, batch loss 0.854380, batch nll 0.441122, batch error rate 12.000000%\n",
      "At minibatch 22700, batch loss 1.172834, batch nll 0.759647, batch error rate 28.000000%\n",
      "At minibatch 22800, batch loss 0.962895, batch nll 0.549794, batch error rate 12.000000%\n",
      "At minibatch 22900, batch loss 0.865277, batch nll 0.452270, batch error rate 20.000000%\n",
      "At minibatch 23000, batch loss 1.213946, batch nll 0.801048, batch error rate 28.000000%\n",
      "At minibatch 23100, batch loss 1.102736, batch nll 0.689940, batch error rate 28.000000%\n",
      "At minibatch 23200, batch loss 0.834005, batch nll 0.421290, batch error rate 12.000000%\n",
      "At minibatch 23300, batch loss 1.000625, batch nll 0.587983, batch error rate 16.000000%\n",
      "At minibatch 23400, batch loss 1.023140, batch nll 0.610588, batch error rate 20.000000%\n",
      "At minibatch 23500, batch loss 0.670942, batch nll 0.258520, batch error rate 12.000000%\n",
      "At minibatch 23600, batch loss 0.897768, batch nll 0.485473, batch error rate 12.000000%\n",
      "At minibatch 23700, batch loss 0.789220, batch nll 0.377045, batch error rate 16.000000%\n",
      "At minibatch 23800, batch loss 1.154615, batch nll 0.742563, batch error rate 28.000000%\n",
      "At minibatch 23900, batch loss 1.082432, batch nll 0.670517, batch error rate 20.000000%\n",
      "At minibatch 24000, batch loss 0.943424, batch nll 0.531669, batch error rate 16.000000%\n",
      "After epoch 15: valid_err_rate: 32.020000% currently going to do 20 epochs\n",
      "After epoch 15: averaged train_err_rate: 16.860000% averaged train nll: 0.511011 averaged train loss: 0.923691\n",
      "At minibatch 24100, batch loss 1.160083, batch nll 0.748385, batch error rate 24.000000%\n",
      "At minibatch 24200, batch loss 0.583705, batch nll 0.172075, batch error rate 0.000000%\n",
      "At minibatch 24300, batch loss 0.920553, batch nll 0.509014, batch error rate 16.000000%\n",
      "At minibatch 24400, batch loss 0.932622, batch nll 0.521146, batch error rate 8.000000%\n",
      "At minibatch 24500, batch loss 0.742458, batch nll 0.331030, batch error rate 4.000000%\n",
      "At minibatch 24600, batch loss 0.996460, batch nll 0.585113, batch error rate 16.000000%\n",
      "At minibatch 24700, batch loss 0.840613, batch nll 0.429337, batch error rate 12.000000%\n",
      "At minibatch 24800, batch loss 0.955341, batch nll 0.544146, batch error rate 16.000000%\n",
      "At minibatch 24900, batch loss 0.930090, batch nll 0.519013, batch error rate 16.000000%\n",
      "At minibatch 25000, batch loss 0.803670, batch nll 0.392698, batch error rate 16.000000%\n",
      "At minibatch 25100, batch loss 1.108735, batch nll 0.697862, batch error rate 20.000000%\n",
      "At minibatch 25200, batch loss 1.017741, batch nll 0.606988, batch error rate 20.000000%\n",
      "At minibatch 25300, batch loss 0.901213, batch nll 0.490582, batch error rate 20.000000%\n",
      "At minibatch 25400, batch loss 0.736976, batch nll 0.326471, batch error rate 4.000000%\n",
      "At minibatch 25500, batch loss 0.802155, batch nll 0.391776, batch error rate 4.000000%\n",
      "At minibatch 25600, batch loss 0.662900, batch nll 0.252603, batch error rate 4.000000%\n",
      "After epoch 16: valid_err_rate: 32.100000% currently going to do 20 epochs\n",
      "After epoch 16: averaged train_err_rate: 15.930000% averaged train nll: 0.487197 averaged train loss: 0.898311\n",
      "At minibatch 25700, batch loss 0.701845, batch nll 0.291578, batch error rate 8.000000%\n",
      "At minibatch 25800, batch loss 1.126778, batch nll 0.716566, batch error rate 24.000000%\n",
      "At minibatch 25900, batch loss 0.717424, batch nll 0.307244, batch error rate 16.000000%\n",
      "At minibatch 26000, batch loss 1.000555, batch nll 0.590422, batch error rate 24.000000%\n",
      "At minibatch 26100, batch loss 0.872479, batch nll 0.462412, batch error rate 28.000000%\n",
      "At minibatch 26200, batch loss 0.893732, batch nll 0.483745, batch error rate 16.000000%\n",
      "At minibatch 26300, batch loss 0.921153, batch nll 0.511257, batch error rate 20.000000%\n",
      "At minibatch 26400, batch loss 1.136581, batch nll 0.726711, batch error rate 36.000000%\n",
      "At minibatch 26500, batch loss 0.773418, batch nll 0.363624, batch error rate 12.000000%\n",
      "At minibatch 26600, batch loss 0.834300, batch nll 0.424574, batch error rate 12.000000%\n",
      "At minibatch 26700, batch loss 0.747042, batch nll 0.337405, batch error rate 8.000000%\n",
      "At minibatch 26800, batch loss 0.768518, batch nll 0.358943, batch error rate 12.000000%\n",
      "At minibatch 26900, batch loss 0.843983, batch nll 0.434520, batch error rate 16.000000%\n",
      "At minibatch 27000, batch loss 0.882919, batch nll 0.473544, batch error rate 20.000000%\n",
      "At minibatch 27100, batch loss 0.771739, batch nll 0.362451, batch error rate 16.000000%\n",
      "At minibatch 27200, batch loss 0.791767, batch nll 0.382575, batch error rate 20.000000%\n",
      "After epoch 17: valid_err_rate: 32.160000% currently going to do 20 epochs\n",
      "After epoch 17: averaged train_err_rate: 14.995000% averaged train nll: 0.462707 averaged train loss: 0.872535\n",
      "At minibatch 27300, batch loss 0.904174, batch nll 0.495005, batch error rate 24.000000%\n",
      "At minibatch 27400, batch loss 0.772862, batch nll 0.363734, batch error rate 8.000000%\n",
      "At minibatch 27500, batch loss 0.811026, batch nll 0.401952, batch error rate 8.000000%\n",
      "At minibatch 27600, batch loss 0.764557, batch nll 0.355506, batch error rate 8.000000%\n",
      "At minibatch 27700, batch loss 1.112611, batch nll 0.703575, batch error rate 16.000000%\n",
      "At minibatch 27800, batch loss 0.896947, batch nll 0.487956, batch error rate 12.000000%\n",
      "At minibatch 27900, batch loss 0.669862, batch nll 0.260961, batch error rate 4.000000%\n",
      "At minibatch 28000, batch loss 0.796345, batch nll 0.387521, batch error rate 12.000000%\n",
      "At minibatch 28100, batch loss 0.733540, batch nll 0.324822, batch error rate 8.000000%\n",
      "At minibatch 28200, batch loss 0.786578, batch nll 0.377918, batch error rate 8.000000%\n",
      "At minibatch 28300, batch loss 0.822448, batch nll 0.413861, batch error rate 12.000000%\n",
      "At minibatch 28400, batch loss 0.587128, batch nll 0.178616, batch error rate 0.000000%\n",
      "At minibatch 28500, batch loss 0.921185, batch nll 0.512755, batch error rate 16.000000%\n",
      "At minibatch 28600, batch loss 0.641220, batch nll 0.232862, batch error rate 8.000000%\n",
      "At minibatch 28700, batch loss 0.914795, batch nll 0.506484, batch error rate 20.000000%\n",
      "At minibatch 28800, batch loss 0.819079, batch nll 0.410855, batch error rate 8.000000%\n",
      "After epoch 18: valid_err_rate: 31.650000% currently going to do 28 epochs\n",
      "After epoch 18: averaged train_err_rate: 14.182500% averaged train nll: 0.442951 averaged train loss: 0.851730\n",
      "At minibatch 28900, batch loss 0.783118, batch nll 0.374926, batch error rate 4.000000%\n",
      "At minibatch 29000, batch loss 0.932322, batch nll 0.524142, batch error rate 16.000000%\n",
      "At minibatch 29100, batch loss 0.783718, batch nll 0.375546, batch error rate 8.000000%\n",
      "At minibatch 29200, batch loss 0.665225, batch nll 0.257079, batch error rate 4.000000%\n",
      "At minibatch 29300, batch loss 0.793726, batch nll 0.385600, batch error rate 12.000000%\n",
      "At minibatch 29400, batch loss 0.821604, batch nll 0.413521, batch error rate 16.000000%\n",
      "At minibatch 29500, batch loss 1.103886, batch nll 0.695850, batch error rate 20.000000%\n",
      "At minibatch 29600, batch loss 0.824273, batch nll 0.416287, batch error rate 12.000000%\n",
      "At minibatch 29700, batch loss 0.727671, batch nll 0.319773, batch error rate 0.000000%\n",
      "At minibatch 29800, batch loss 0.899364, batch nll 0.491549, batch error rate 12.000000%\n",
      "At minibatch 29900, batch loss 0.780577, batch nll 0.372788, batch error rate 12.000000%\n",
      "At minibatch 30000, batch loss 0.887421, batch nll 0.479653, batch error rate 28.000000%\n",
      "At minibatch 30100, batch loss 0.821849, batch nll 0.414119, batch error rate 16.000000%\n",
      "At minibatch 30200, batch loss 0.799611, batch nll 0.391968, batch error rate 16.000000%\n",
      "At minibatch 30300, batch loss 0.819784, batch nll 0.412224, batch error rate 8.000000%\n",
      "At minibatch 30400, batch loss 0.876566, batch nll 0.469061, batch error rate 16.000000%\n",
      "After epoch 19: valid_err_rate: 31.590000% currently going to do 29 epochs\n",
      "After epoch 19: averaged train_err_rate: 13.457500% averaged train nll: 0.423010 averaged train loss: 0.830945\n",
      "At minibatch 30500, batch loss 0.710919, batch nll 0.303442, batch error rate 4.000000%\n",
      "At minibatch 30600, batch loss 0.822410, batch nll 0.414962, batch error rate 16.000000%\n",
      "At minibatch 30700, batch loss 0.675499, batch nll 0.268062, batch error rate 0.000000%\n",
      "At minibatch 30800, batch loss 0.760025, batch nll 0.352581, batch error rate 12.000000%\n",
      "At minibatch 30900, batch loss 0.841579, batch nll 0.434171, batch error rate 12.000000%\n",
      "At minibatch 31000, batch loss 0.816183, batch nll 0.408828, batch error rate 16.000000%\n",
      "At minibatch 31100, batch loss 0.626035, batch nll 0.218700, batch error rate 4.000000%\n",
      "At minibatch 31200, batch loss 0.838097, batch nll 0.430819, batch error rate 24.000000%\n",
      "At minibatch 31300, batch loss 0.729460, batch nll 0.322221, batch error rate 8.000000%\n",
      "At minibatch 31400, batch loss 0.633040, batch nll 0.225850, batch error rate 4.000000%\n",
      "At minibatch 31500, batch loss 0.821591, batch nll 0.414439, batch error rate 8.000000%\n",
      "At minibatch 31600, batch loss 0.680600, batch nll 0.273494, batch error rate 4.000000%\n",
      "At minibatch 31700, batch loss 1.091650, batch nll 0.684591, batch error rate 24.000000%\n",
      "At minibatch 31800, batch loss 0.776529, batch nll 0.369514, batch error rate 8.000000%\n",
      "At minibatch 31900, batch loss 0.995730, batch nll 0.588804, batch error rate 20.000000%\n",
      "At minibatch 32000, batch loss 0.837299, batch nll 0.430460, batch error rate 16.000000%\n",
      "After epoch 20: valid_err_rate: 31.700000% currently going to do 29 epochs\n",
      "After epoch 20: averaged train_err_rate: 12.557500% averaged train nll: 0.402844 averaged train loss: 0.810100\n",
      "At minibatch 32100, batch loss 0.923573, batch nll 0.516729, batch error rate 24.000000%\n",
      "At minibatch 32200, batch loss 0.778251, batch nll 0.371401, batch error rate 12.000000%\n",
      "At minibatch 32300, batch loss 0.694142, batch nll 0.287294, batch error rate 4.000000%\n",
      "At minibatch 32400, batch loss 0.991429, batch nll 0.584619, batch error rate 20.000000%\n",
      "At minibatch 32500, batch loss 0.704175, batch nll 0.297402, batch error rate 4.000000%\n",
      "At minibatch 32600, batch loss 0.704132, batch nll 0.297391, batch error rate 4.000000%\n",
      "At minibatch 32700, batch loss 0.774813, batch nll 0.368092, batch error rate 16.000000%\n",
      "At minibatch 32800, batch loss 0.950050, batch nll 0.543368, batch error rate 16.000000%\n",
      "At minibatch 32900, batch loss 1.031024, batch nll 0.624340, batch error rate 20.000000%\n",
      "At minibatch 33000, batch loss 0.656293, batch nll 0.249672, batch error rate 4.000000%\n",
      "At minibatch 33100, batch loss 0.830908, batch nll 0.424328, batch error rate 16.000000%\n",
      "At minibatch 33200, batch loss 0.978064, batch nll 0.571525, batch error rate 20.000000%\n",
      "At minibatch 33300, batch loss 0.740575, batch nll 0.334090, batch error rate 12.000000%\n",
      "At minibatch 33400, batch loss 0.998659, batch nll 0.592204, batch error rate 8.000000%\n",
      "At minibatch 33500, batch loss 0.743530, batch nll 0.337141, batch error rate 4.000000%\n",
      "At minibatch 33600, batch loss 0.895055, batch nll 0.488713, batch error rate 24.000000%\n",
      "After epoch 21: valid_err_rate: 31.500000% currently going to do 32 epochs\n",
      "After epoch 21: averaged train_err_rate: 11.815000% averaged train nll: 0.386136 averaged train loss: 0.792802\n",
      "At minibatch 33700, batch loss 0.834743, batch nll 0.428426, batch error rate 12.000000%\n",
      "At minibatch 33800, batch loss 0.740240, batch nll 0.333922, batch error rate 12.000000%\n",
      "At minibatch 33900, batch loss 0.804847, batch nll 0.398538, batch error rate 12.000000%\n",
      "At minibatch 34000, batch loss 0.968480, batch nll 0.562160, batch error rate 28.000000%\n",
      "At minibatch 34100, batch loss 0.904384, batch nll 0.498096, batch error rate 12.000000%\n",
      "At minibatch 34200, batch loss 0.905359, batch nll 0.499084, batch error rate 12.000000%\n",
      "At minibatch 34300, batch loss 0.831674, batch nll 0.425451, batch error rate 16.000000%\n",
      "At minibatch 34400, batch loss 0.601440, batch nll 0.195251, batch error rate 8.000000%\n",
      "At minibatch 34500, batch loss 0.821214, batch nll 0.415082, batch error rate 12.000000%\n",
      "At minibatch 34600, batch loss 0.773428, batch nll 0.367339, batch error rate 8.000000%\n",
      "At minibatch 34700, batch loss 0.784771, batch nll 0.378715, batch error rate 16.000000%\n",
      "At minibatch 34800, batch loss 0.697017, batch nll 0.290986, batch error rate 12.000000%\n",
      "At minibatch 34900, batch loss 0.653455, batch nll 0.247461, batch error rate 0.000000%\n",
      "At minibatch 35000, batch loss 0.971271, batch nll 0.565308, batch error rate 12.000000%\n",
      "At minibatch 35100, batch loss 0.806690, batch nll 0.400730, batch error rate 12.000000%\n",
      "At minibatch 35200, batch loss 0.865555, batch nll 0.459659, batch error rate 24.000000%\n",
      "After epoch 22: valid_err_rate: 31.810000% currently going to do 32 epochs\n",
      "After epoch 22: averaged train_err_rate: 11.167500% averaged train nll: 0.369438 averaged train loss: 0.775599\n",
      "At minibatch 35300, batch loss 0.689482, batch nll 0.283588, batch error rate 4.000000%\n",
      "At minibatch 35400, batch loss 0.753764, batch nll 0.347872, batch error rate 16.000000%\n",
      "At minibatch 35500, batch loss 0.824744, batch nll 0.418877, batch error rate 20.000000%\n",
      "At minibatch 35600, batch loss 0.654019, batch nll 0.248150, batch error rate 4.000000%\n",
      "At minibatch 35700, batch loss 0.744866, batch nll 0.339024, batch error rate 12.000000%\n",
      "At minibatch 35800, batch loss 0.638189, batch nll 0.232366, batch error rate 4.000000%\n",
      "At minibatch 35900, batch loss 0.780441, batch nll 0.374637, batch error rate 16.000000%\n",
      "At minibatch 36000, batch loss 0.815313, batch nll 0.409548, batch error rate 12.000000%\n",
      "At minibatch 36100, batch loss 1.010907, batch nll 0.605157, batch error rate 16.000000%\n",
      "At minibatch 36200, batch loss 0.599218, batch nll 0.193500, batch error rate 4.000000%\n",
      "At minibatch 36300, batch loss 0.651509, batch nll 0.245813, batch error rate 4.000000%\n",
      "At minibatch 36400, batch loss 0.823759, batch nll 0.418088, batch error rate 8.000000%\n",
      "At minibatch 36500, batch loss 1.101995, batch nll 0.696344, batch error rate 28.000000%\n",
      "At minibatch 36600, batch loss 0.965869, batch nll 0.560263, batch error rate 16.000000%\n",
      "At minibatch 36700, batch loss 0.832425, batch nll 0.426860, batch error rate 16.000000%\n",
      "At minibatch 36800, batch loss 0.603617, batch nll 0.198063, batch error rate 8.000000%\n",
      "After epoch 23: valid_err_rate: 31.480000% currently going to do 35 epochs\n",
      "After epoch 23: averaged train_err_rate: 10.427500% averaged train nll: 0.353537 averaged train loss: 0.759294\n",
      "At minibatch 36900, batch loss 0.875715, batch nll 0.470179, batch error rate 12.000000%\n",
      "At minibatch 37000, batch loss 0.550056, batch nll 0.144526, batch error rate 0.000000%\n",
      "At minibatch 37100, batch loss 1.013481, batch nll 0.607956, batch error rate 20.000000%\n",
      "At minibatch 37200, batch loss 0.517701, batch nll 0.112174, batch error rate 0.000000%\n",
      "At minibatch 37300, batch loss 0.599266, batch nll 0.193750, batch error rate 0.000000%\n",
      "At minibatch 37400, batch loss 0.562114, batch nll 0.156621, batch error rate 0.000000%\n",
      "At minibatch 37500, batch loss 0.830981, batch nll 0.425514, batch error rate 20.000000%\n",
      "At minibatch 37600, batch loss 0.922071, batch nll 0.516619, batch error rate 8.000000%\n",
      "At minibatch 37700, batch loss 0.739451, batch nll 0.334011, batch error rate 4.000000%\n",
      "At minibatch 37800, batch loss 0.835910, batch nll 0.430493, batch error rate 12.000000%\n",
      "At minibatch 37900, batch loss 0.818334, batch nll 0.412969, batch error rate 16.000000%\n",
      "At minibatch 38000, batch loss 0.793503, batch nll 0.388156, batch error rate 12.000000%\n",
      "At minibatch 38100, batch loss 0.803374, batch nll 0.398055, batch error rate 12.000000%\n",
      "At minibatch 38200, batch loss 0.688017, batch nll 0.282722, batch error rate 4.000000%\n",
      "At minibatch 38300, batch loss 0.907645, batch nll 0.502363, batch error rate 20.000000%\n",
      "At minibatch 38400, batch loss 0.698064, batch nll 0.292803, batch error rate 12.000000%\n",
      "After epoch 24: valid_err_rate: 31.610000% currently going to do 35 epochs\n",
      "After epoch 24: averaged train_err_rate: 9.972500% averaged train nll: 0.338517 averaged train loss: 0.743950\n",
      "At minibatch 38500, batch loss 0.676825, batch nll 0.271546, batch error rate 4.000000%\n",
      "At minibatch 38600, batch loss 0.899018, batch nll 0.493726, batch error rate 12.000000%\n",
      "At minibatch 38700, batch loss 0.564810, batch nll 0.159513, batch error rate 0.000000%\n",
      "At minibatch 38800, batch loss 0.672021, batch nll 0.266741, batch error rate 8.000000%\n",
      "At minibatch 38900, batch loss 0.547054, batch nll 0.141783, batch error rate 0.000000%\n",
      "At minibatch 39000, batch loss 0.745755, batch nll 0.340506, batch error rate 8.000000%\n",
      "At minibatch 39100, batch loss 0.923768, batch nll 0.518543, batch error rate 20.000000%\n",
      "At minibatch 39200, batch loss 0.910967, batch nll 0.505766, batch error rate 16.000000%\n",
      "At minibatch 39300, batch loss 0.628144, batch nll 0.222941, batch error rate 8.000000%\n",
      "At minibatch 39400, batch loss 0.713174, batch nll 0.307978, batch error rate 8.000000%\n",
      "At minibatch 39500, batch loss 0.724425, batch nll 0.319267, batch error rate 12.000000%\n",
      "At minibatch 39600, batch loss 0.858471, batch nll 0.453322, batch error rate 16.000000%\n",
      "At minibatch 39700, batch loss 0.726459, batch nll 0.321318, batch error rate 8.000000%\n",
      "At minibatch 39800, batch loss 0.814157, batch nll 0.409004, batch error rate 12.000000%\n",
      "At minibatch 39900, batch loss 0.822203, batch nll 0.417092, batch error rate 12.000000%\n",
      "At minibatch 40000, batch loss 0.820467, batch nll 0.415404, batch error rate 16.000000%\n",
      "After epoch 25: valid_err_rate: 31.890000% currently going to do 35 epochs\n",
      "After epoch 25: averaged train_err_rate: 9.335000% averaged train nll: 0.322075 averaged train loss: 0.727284\n",
      "At minibatch 40100, batch loss 0.751979, batch nll 0.346907, batch error rate 8.000000%\n",
      "At minibatch 40200, batch loss 0.671534, batch nll 0.266459, batch error rate 4.000000%\n",
      "At minibatch 40300, batch loss 0.717363, batch nll 0.312283, batch error rate 12.000000%\n",
      "At minibatch 40400, batch loss 0.591022, batch nll 0.185927, batch error rate 4.000000%\n",
      "At minibatch 40500, batch loss 0.751179, batch nll 0.346097, batch error rate 12.000000%\n",
      "At minibatch 40600, batch loss 0.778399, batch nll 0.373331, batch error rate 4.000000%\n",
      "At minibatch 40700, batch loss 0.605963, batch nll 0.200890, batch error rate 4.000000%\n",
      "At minibatch 40800, batch loss 0.558568, batch nll 0.153501, batch error rate 4.000000%\n",
      "At minibatch 40900, batch loss 0.648110, batch nll 0.243074, batch error rate 4.000000%\n",
      "At minibatch 41000, batch loss 0.672292, batch nll 0.267283, batch error rate 8.000000%\n",
      "At minibatch 41100, batch loss 0.794236, batch nll 0.389245, batch error rate 16.000000%\n",
      "At minibatch 41200, batch loss 0.592355, batch nll 0.187387, batch error rate 4.000000%\n",
      "At minibatch 41300, batch loss 0.643376, batch nll 0.238427, batch error rate 12.000000%\n",
      "At minibatch 41400, batch loss 0.748924, batch nll 0.343992, batch error rate 12.000000%\n",
      "At minibatch 41500, batch loss 0.810092, batch nll 0.405202, batch error rate 4.000000%\n",
      "At minibatch 41600, batch loss 0.631510, batch nll 0.226654, batch error rate 4.000000%\n",
      "After epoch 26: valid_err_rate: 31.610000% currently going to do 35 epochs\n",
      "After epoch 26: averaged train_err_rate: 8.705000% averaged train nll: 0.309041 averaged train loss: 0.714062\n",
      "At minibatch 41700, batch loss 0.782618, batch nll 0.377753, batch error rate 12.000000%\n",
      "At minibatch 41800, batch loss 0.675446, batch nll 0.270574, batch error rate 0.000000%\n",
      "At minibatch 41900, batch loss 0.639554, batch nll 0.234692, batch error rate 4.000000%\n",
      "At minibatch 42000, batch loss 0.626244, batch nll 0.221390, batch error rate 4.000000%\n",
      "At minibatch 42100, batch loss 1.175305, batch nll 0.770444, batch error rate 32.000000%\n",
      "At minibatch 42200, batch loss 0.685918, batch nll 0.281083, batch error rate 4.000000%\n",
      "At minibatch 42300, batch loss 0.801533, batch nll 0.396696, batch error rate 16.000000%\n",
      "At minibatch 42400, batch loss 0.571605, batch nll 0.166764, batch error rate 0.000000%\n",
      "At minibatch 42500, batch loss 0.717792, batch nll 0.312964, batch error rate 16.000000%\n",
      "At minibatch 42600, batch loss 0.606367, batch nll 0.201560, batch error rate 0.000000%\n",
      "At minibatch 42700, batch loss 0.591860, batch nll 0.187055, batch error rate 0.000000%\n",
      "At minibatch 42800, batch loss 0.705423, batch nll 0.300633, batch error rate 12.000000%\n",
      "At minibatch 42900, batch loss 0.757820, batch nll 0.353050, batch error rate 16.000000%\n",
      "At minibatch 43000, batch loss 0.879111, batch nll 0.474364, batch error rate 24.000000%\n",
      "At minibatch 43100, batch loss 0.603491, batch nll 0.198772, batch error rate 4.000000%\n",
      "At minibatch 43200, batch loss 0.636654, batch nll 0.231964, batch error rate 8.000000%\n",
      "After epoch 27: valid_err_rate: 31.580000% currently going to do 35 epochs\n",
      "After epoch 27: averaged train_err_rate: 8.097500% averaged train nll: 0.297142 averaged train loss: 0.701958\n",
      "At minibatch 43300, batch loss 0.680697, batch nll 0.276003, batch error rate 12.000000%\n",
      "At minibatch 43400, batch loss 0.792838, batch nll 0.388149, batch error rate 12.000000%\n",
      "At minibatch 43500, batch loss 0.686087, batch nll 0.281403, batch error rate 12.000000%\n",
      "At minibatch 43600, batch loss 0.774802, batch nll 0.370109, batch error rate 12.000000%\n",
      "At minibatch 43700, batch loss 0.901658, batch nll 0.496986, batch error rate 12.000000%\n",
      "At minibatch 43800, batch loss 0.581239, batch nll 0.176555, batch error rate 4.000000%\n",
      "At minibatch 43900, batch loss 0.779469, batch nll 0.374789, batch error rate 12.000000%\n",
      "At minibatch 44000, batch loss 0.714891, batch nll 0.310241, batch error rate 8.000000%\n",
      "At minibatch 44100, batch loss 0.664595, batch nll 0.259938, batch error rate 4.000000%\n",
      "At minibatch 44200, batch loss 0.769216, batch nll 0.364557, batch error rate 12.000000%\n",
      "At minibatch 44300, batch loss 0.902330, batch nll 0.497686, batch error rate 8.000000%\n",
      "At minibatch 44400, batch loss 0.716847, batch nll 0.312214, batch error rate 8.000000%\n",
      "At minibatch 44500, batch loss 0.687383, batch nll 0.282769, batch error rate 4.000000%\n",
      "At minibatch 44600, batch loss 0.644944, batch nll 0.240331, batch error rate 4.000000%\n",
      "At minibatch 44700, batch loss 0.574281, batch nll 0.169678, batch error rate 0.000000%\n",
      "At minibatch 44800, batch loss 0.596732, batch nll 0.192142, batch error rate 0.000000%\n",
      "After epoch 28: valid_err_rate: 32.160000% currently going to do 35 epochs\n",
      "After epoch 28: averaged train_err_rate: 7.662500% averaged train nll: 0.285561 averaged train loss: 0.690217\n",
      "At minibatch 44900, batch loss 0.698312, batch nll 0.293704, batch error rate 4.000000%\n",
      "At minibatch 45000, batch loss 0.843977, batch nll 0.439382, batch error rate 16.000000%\n",
      "At minibatch 45100, batch loss 0.627779, batch nll 0.223183, batch error rate 8.000000%\n",
      "At minibatch 45200, batch loss 0.621534, batch nll 0.216964, batch error rate 0.000000%\n",
      "At minibatch 45300, batch loss 0.708004, batch nll 0.303418, batch error rate 12.000000%\n",
      "At minibatch 45400, batch loss 0.617933, batch nll 0.213351, batch error rate 0.000000%\n",
      "At minibatch 45500, batch loss 0.645257, batch nll 0.240677, batch error rate 4.000000%\n",
      "At minibatch 45600, batch loss 0.741104, batch nll 0.336534, batch error rate 12.000000%\n",
      "At minibatch 45700, batch loss 0.827040, batch nll 0.422492, batch error rate 8.000000%\n",
      "At minibatch 45800, batch loss 0.543847, batch nll 0.139309, batch error rate 0.000000%\n",
      "At minibatch 45900, batch loss 0.719879, batch nll 0.315329, batch error rate 8.000000%\n",
      "At minibatch 46000, batch loss 0.573178, batch nll 0.168654, batch error rate 4.000000%\n",
      "At minibatch 46100, batch loss 0.669160, batch nll 0.264649, batch error rate 0.000000%\n",
      "At minibatch 46200, batch loss 0.658053, batch nll 0.253548, batch error rate 12.000000%\n",
      "At minibatch 46300, batch loss 0.561134, batch nll 0.156642, batch error rate 4.000000%\n",
      "At minibatch 46400, batch loss 0.727483, batch nll 0.322996, batch error rate 12.000000%\n",
      "After epoch 29: valid_err_rate: 31.790000% currently going to do 35 epochs\n",
      "After epoch 29: averaged train_err_rate: 7.210000% averaged train nll: 0.273074 averaged train loss: 0.677630\n",
      "At minibatch 46500, batch loss 0.586332, batch nll 0.181839, batch error rate 4.000000%\n",
      "At minibatch 46600, batch loss 0.599762, batch nll 0.195260, batch error rate 4.000000%\n",
      "At minibatch 46700, batch loss 0.790691, batch nll 0.386196, batch error rate 12.000000%\n",
      "At minibatch 46800, batch loss 0.777986, batch nll 0.373495, batch error rate 12.000000%\n",
      "At minibatch 46900, batch loss 0.683807, batch nll 0.279322, batch error rate 8.000000%\n",
      "At minibatch 47000, batch loss 0.718209, batch nll 0.313726, batch error rate 16.000000%\n",
      "At minibatch 47100, batch loss 0.648510, batch nll 0.244024, batch error rate 12.000000%\n",
      "At minibatch 47200, batch loss 0.601569, batch nll 0.197095, batch error rate 4.000000%\n",
      "At minibatch 47300, batch loss 0.715951, batch nll 0.311482, batch error rate 8.000000%\n",
      "At minibatch 47400, batch loss 0.738119, batch nll 0.333659, batch error rate 12.000000%\n",
      "At minibatch 47500, batch loss 0.626852, batch nll 0.222408, batch error rate 4.000000%\n",
      "At minibatch 47600, batch loss 0.737871, batch nll 0.333447, batch error rate 8.000000%\n",
      "At minibatch 47700, batch loss 0.697230, batch nll 0.292822, batch error rate 12.000000%\n",
      "At minibatch 47800, batch loss 0.530573, batch nll 0.126177, batch error rate 4.000000%\n",
      "At minibatch 47900, batch loss 0.656248, batch nll 0.251875, batch error rate 8.000000%\n",
      "At minibatch 48000, batch loss 0.555597, batch nll 0.151236, batch error rate 4.000000%\n",
      "After epoch 30: valid_err_rate: 31.620000% currently going to do 35 epochs\n",
      "After epoch 30: averaged train_err_rate: 6.797500% averaged train nll: 0.262509 averaged train loss: 0.666966\n",
      "At minibatch 48100, batch loss 0.678213, batch nll 0.273841, batch error rate 4.000000%\n",
      "At minibatch 48200, batch loss 0.785003, batch nll 0.380629, batch error rate 4.000000%\n",
      "At minibatch 48300, batch loss 0.740446, batch nll 0.336073, batch error rate 4.000000%\n",
      "At minibatch 48400, batch loss 0.646875, batch nll 0.242509, batch error rate 8.000000%\n",
      "At minibatch 48500, batch loss 0.679952, batch nll 0.275602, batch error rate 8.000000%\n",
      "At minibatch 48600, batch loss 0.553235, batch nll 0.148887, batch error rate 0.000000%\n",
      "At minibatch 48700, batch loss 0.705305, batch nll 0.300941, batch error rate 8.000000%\n",
      "At minibatch 48800, batch loss 0.695203, batch nll 0.290836, batch error rate 8.000000%\n",
      "At minibatch 48900, batch loss 0.690691, batch nll 0.286342, batch error rate 8.000000%\n",
      "At minibatch 49000, batch loss 0.683967, batch nll 0.279621, batch error rate 8.000000%\n",
      "At minibatch 49100, batch loss 0.664289, batch nll 0.259948, batch error rate 4.000000%\n",
      "At minibatch 49200, batch loss 0.668602, batch nll 0.264273, batch error rate 8.000000%\n",
      "At minibatch 49300, batch loss 0.580884, batch nll 0.176555, batch error rate 4.000000%\n",
      "At minibatch 49400, batch loss 0.641383, batch nll 0.237061, batch error rate 12.000000%\n",
      "At minibatch 49500, batch loss 0.588476, batch nll 0.184170, batch error rate 4.000000%\n",
      "At minibatch 49600, batch loss 0.642429, batch nll 0.238146, batch error rate 8.000000%\n",
      "After epoch 31: valid_err_rate: 31.670000% currently going to do 35 epochs\n",
      "After epoch 31: averaged train_err_rate: 6.157500% averaged train nll: 0.250603 averaged train loss: 0.654951\n",
      "At minibatch 49700, batch loss 0.518477, batch nll 0.114184, batch error rate 0.000000%\n",
      "At minibatch 49800, batch loss 0.656898, batch nll 0.252605, batch error rate 4.000000%\n",
      "At minibatch 49900, batch loss 0.759485, batch nll 0.355204, batch error rate 12.000000%\n",
      "At minibatch 50000, batch loss 0.607407, batch nll 0.203140, batch error rate 8.000000%\n",
      "At minibatch 50100, batch loss 0.558256, batch nll 0.153991, batch error rate 8.000000%\n",
      "At minibatch 50200, batch loss 0.657656, batch nll 0.253395, batch error rate 4.000000%\n",
      "At minibatch 50300, batch loss 0.734857, batch nll 0.330621, batch error rate 12.000000%\n",
      "At minibatch 50400, batch loss 0.679729, batch nll 0.275484, batch error rate 4.000000%\n",
      "At minibatch 50500, batch loss 0.687497, batch nll 0.283257, batch error rate 12.000000%\n",
      "At minibatch 50600, batch loss 0.600501, batch nll 0.196255, batch error rate 4.000000%\n",
      "At minibatch 50700, batch loss 0.619331, batch nll 0.215096, batch error rate 0.000000%\n",
      "At minibatch 50800, batch loss 0.874045, batch nll 0.469805, batch error rate 20.000000%\n",
      "At minibatch 50900, batch loss 0.576397, batch nll 0.172169, batch error rate 0.000000%\n",
      "At minibatch 51000, batch loss 0.763363, batch nll 0.359161, batch error rate 12.000000%\n",
      "At minibatch 51100, batch loss 0.605561, batch nll 0.201367, batch error rate 8.000000%\n",
      "At minibatch 51200, batch loss 0.711686, batch nll 0.307507, batch error rate 8.000000%\n",
      "After epoch 32: valid_err_rate: 31.990000% currently going to do 35 epochs\n",
      "After epoch 32: averaged train_err_rate: 5.870000% averaged train nll: 0.241665 averaged train loss: 0.645913\n",
      "At minibatch 51300, batch loss 0.576098, batch nll 0.171921, batch error rate 0.000000%\n",
      "At minibatch 51400, batch loss 0.533345, batch nll 0.129173, batch error rate 4.000000%\n",
      "At minibatch 51500, batch loss 0.608577, batch nll 0.204401, batch error rate 4.000000%\n",
      "At minibatch 51600, batch loss 0.601361, batch nll 0.197186, batch error rate 8.000000%\n",
      "At minibatch 51700, batch loss 0.637905, batch nll 0.233733, batch error rate 8.000000%\n",
      "At minibatch 51800, batch loss 0.675454, batch nll 0.271282, batch error rate 8.000000%\n",
      "At minibatch 51900, batch loss 0.522508, batch nll 0.118335, batch error rate 0.000000%\n",
      "At minibatch 52000, batch loss 0.567026, batch nll 0.162865, batch error rate 0.000000%\n",
      "At minibatch 52100, batch loss 0.599026, batch nll 0.194870, batch error rate 4.000000%\n",
      "At minibatch 52200, batch loss 0.574143, batch nll 0.170000, batch error rate 0.000000%\n",
      "At minibatch 52300, batch loss 0.602456, batch nll 0.198324, batch error rate 4.000000%\n",
      "At minibatch 52400, batch loss 0.555807, batch nll 0.151681, batch error rate 0.000000%\n",
      "At minibatch 52500, batch loss 0.705930, batch nll 0.301825, batch error rate 12.000000%\n",
      "At minibatch 52600, batch loss 0.607757, batch nll 0.203655, batch error rate 4.000000%\n",
      "At minibatch 52700, batch loss 0.689061, batch nll 0.284986, batch error rate 8.000000%\n",
      "At minibatch 52800, batch loss 0.664862, batch nll 0.260793, batch error rate 4.000000%\n",
      "After epoch 33: valid_err_rate: 31.760000% currently going to do 35 epochs\n",
      "After epoch 33: averaged train_err_rate: 5.575000% averaged train nll: 0.232872 averaged train loss: 0.637017\n",
      "At minibatch 52900, batch loss 0.706367, batch nll 0.302287, batch error rate 4.000000%\n",
      "At minibatch 53000, batch loss 0.705291, batch nll 0.301201, batch error rate 4.000000%\n",
      "At minibatch 53100, batch loss 0.617078, batch nll 0.213005, batch error rate 4.000000%\n",
      "At minibatch 53200, batch loss 0.664918, batch nll 0.260839, batch error rate 8.000000%\n",
      "At minibatch 53300, batch loss 0.605701, batch nll 0.201622, batch error rate 4.000000%\n",
      "At minibatch 53400, batch loss 0.571892, batch nll 0.167822, batch error rate 0.000000%\n",
      "At minibatch 53500, batch loss 0.507643, batch nll 0.103586, batch error rate 0.000000%\n",
      "At minibatch 53600, batch loss 0.668324, batch nll 0.264268, batch error rate 8.000000%\n",
      "At minibatch 53700, batch loss 0.674497, batch nll 0.270449, batch error rate 8.000000%\n",
      "At minibatch 53800, batch loss 0.565636, batch nll 0.161601, batch error rate 4.000000%\n",
      "At minibatch 53900, batch loss 0.576087, batch nll 0.172064, batch error rate 8.000000%\n",
      "At minibatch 54000, batch loss 0.694495, batch nll 0.290491, batch error rate 8.000000%\n",
      "At minibatch 54100, batch loss 0.604582, batch nll 0.200583, batch error rate 4.000000%\n",
      "At minibatch 54200, batch loss 0.559506, batch nll 0.155509, batch error rate 0.000000%\n",
      "At minibatch 54300, batch loss 0.732347, batch nll 0.328347, batch error rate 8.000000%\n",
      "At minibatch 54400, batch loss 0.738441, batch nll 0.334457, batch error rate 8.000000%\n",
      "After epoch 34: valid_err_rate: 31.870000% currently going to do 35 epochs\n",
      "After epoch 34: averaged train_err_rate: 5.175000% averaged train nll: 0.223718 averaged train loss: 0.627762\n",
      "At minibatch 54500, batch loss 0.687015, batch nll 0.283049, batch error rate 4.000000%\n",
      "At minibatch 54600, batch loss 0.725008, batch nll 0.321043, batch error rate 4.000000%\n",
      "At minibatch 54700, batch loss 0.612542, batch nll 0.208577, batch error rate 8.000000%\n",
      "At minibatch 54800, batch loss 0.575940, batch nll 0.171975, batch error rate 4.000000%\n",
      "At minibatch 54900, batch loss 0.688914, batch nll 0.284953, batch error rate 8.000000%\n",
      "At minibatch 55000, batch loss 0.628455, batch nll 0.224503, batch error rate 8.000000%\n",
      "At minibatch 55100, batch loss 0.678029, batch nll 0.274082, batch error rate 12.000000%\n",
      "At minibatch 55200, batch loss 0.552335, batch nll 0.148400, batch error rate 0.000000%\n",
      "At minibatch 55300, batch loss 0.519253, batch nll 0.115325, batch error rate 0.000000%\n",
      "At minibatch 55400, batch loss 0.693929, batch nll 0.290003, batch error rate 4.000000%\n",
      "At minibatch 55500, batch loss 0.537592, batch nll 0.133670, batch error rate 4.000000%\n",
      "At minibatch 55600, batch loss 0.574634, batch nll 0.170726, batch error rate 0.000000%\n",
      "At minibatch 55700, batch loss 0.666088, batch nll 0.262191, batch error rate 8.000000%\n",
      "At minibatch 55800, batch loss 0.589894, batch nll 0.186003, batch error rate 4.000000%\n",
      "At minibatch 55900, batch loss 0.719320, batch nll 0.315427, batch error rate 16.000000%\n",
      "At minibatch 56000, batch loss 0.562199, batch nll 0.158320, batch error rate 4.000000%\n",
      "After epoch 35: valid_err_rate: 32.020000% currently going to do 35 epochs\n",
      "After epoch 35: averaged train_err_rate: 4.930000% averaged train nll: 0.215554 averaged train loss: 0.619488\n",
      "At minibatch 56100, batch loss 0.560646, batch nll 0.156754, batch error rate 4.000000%\n",
      "At minibatch 56200, batch loss 0.593770, batch nll 0.189870, batch error rate 8.000000%\n",
      "At minibatch 56300, batch loss 0.649769, batch nll 0.245871, batch error rate 8.000000%\n",
      "At minibatch 56400, batch loss 0.619141, batch nll 0.215262, batch error rate 4.000000%\n",
      "At minibatch 56500, batch loss 0.529706, batch nll 0.125841, batch error rate 0.000000%\n",
      "At minibatch 56600, batch loss 0.513213, batch nll 0.109359, batch error rate 0.000000%\n",
      "At minibatch 56700, batch loss 0.722727, batch nll 0.318868, batch error rate 8.000000%\n",
      "At minibatch 56800, batch loss 0.555614, batch nll 0.151772, batch error rate 4.000000%\n",
      "At minibatch 56900, batch loss 0.617717, batch nll 0.213881, batch error rate 4.000000%\n",
      "At minibatch 57000, batch loss 0.593706, batch nll 0.189888, batch error rate 4.000000%\n",
      "At minibatch 57100, batch loss 0.583685, batch nll 0.179872, batch error rate 4.000000%\n",
      "At minibatch 57200, batch loss 0.580372, batch nll 0.176575, batch error rate 0.000000%\n",
      "At minibatch 57300, batch loss 0.596596, batch nll 0.192800, batch error rate 0.000000%\n",
      "At minibatch 57400, batch loss 0.515549, batch nll 0.111752, batch error rate 0.000000%\n",
      "At minibatch 57500, batch loss 0.510417, batch nll 0.106619, batch error rate 0.000000%\n",
      "At minibatch 57600, batch loss 0.597617, batch nll 0.193821, batch error rate 0.000000%\n",
      "After epoch 36: valid_err_rate: 32.060000% currently going to do 35 epochs\n",
      "After epoch 36: averaged train_err_rate: 4.420000% averaged train nll: 0.207542 averaged train loss: 0.611385\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "while e < number_of_epochs: #This loop goes over epochs\n",
    "    e += 1\n",
    "    #First train on all data from this batch\n",
    "    \n",
    "    epoch_start_i = i\n",
    "    \n",
    "    for X_batch, Y_batch in cifar_train_stream.get_epoch_iterator(): \n",
    "        i += 1\n",
    "        \n",
    "        K = 2000\n",
    "        lrate = 4e-3 * K / np.maximum(K, i)\n",
    "        momentum=0.9\n",
    "        \n",
    "        L, err_rate, nll, wdec = train_step(X_batch, Y_batch, lrate, momentum)\n",
    "        \n",
    "        #print [p.get_value().ravel()[:10] for p in model_parameters]\n",
    "        #print [p.get_value().ravel()[:10] for p in velocities]\n",
    "        \n",
    "        \n",
    "        train_loss.append((i,L))\n",
    "        train_erros.append((i,err_rate))\n",
    "        train_nll.append((i,nll))\n",
    "        if i % 100 == 0:\n",
    "            print(\"At minibatch %d, batch loss %f, batch nll %f, batch error rate %f%%\" % (i, L, nll, err_rate*100))\n",
    "        \n",
    "    # After an epoch compute validation error\n",
    "    val_error_rate = compute_error_rate(cifar_validation_stream)\n",
    "    if val_error_rate < best_valid_error_rate:\n",
    "        number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion+1)\n",
    "        best_valid_error_rate = val_error_rate\n",
    "        best_params = snapshot_parameters()\n",
    "        best_params_epoch = e\n",
    "    validation_errors.append((i,val_error_rate))\n",
    "    print(\"After epoch %d: valid_err_rate: %f%% currently going to do %d epochs\" %(\n",
    "        e, val_error_rate*100, number_of_epochs))\n",
    "    print(\"After epoch %d: averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" %(\n",
    "        e, np.mean(np.asarray(train_erros)[epoch_start_i:,1])*100, \n",
    "        np.mean(np.asarray(train_nll)[epoch_start_i:,1]),\n",
    "        np.mean(np.asarray(train_loss)[epoch_start_i:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting network parameters from after epoch 23\n",
      "Test error rate is 32.720000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1f39f85e10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAECCAYAAAAVYxsVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f4eb8d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Setting network parameters from after epoch %d\" %(best_params_epoch))\n",
    "load_parameters(best_params)\n",
    "\n",
    "print(\"Test error rate is %f%%\" %(compute_error_rate(cifar_test_stream)*100.0,))\n",
    "\n",
    "subplot(2,1,1)\n",
    "train_nll_a = np.array(train_nll)\n",
    "semilogy(train_nll_a[:,0], train_nll_a[:,1], label='batch train nll')\n",
    "legend()\n",
    "\n",
    "subplot(2,1,2)\n",
    "train_erros_a = np.array(train_erros)\n",
    "plot(train_erros_a[:,0], train_erros_a[:,1], label='batch train error rate')\n",
    "validation_errors_a = np.array(validation_errors)\n",
    "plot(validation_errors_a[:,0], validation_errors_a[:,1], label='validation error rate', color='r')\n",
    "ylim(0,0.2)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACWCAYAAAAVI9lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACJdJREFUeJzt3V1MHXYdxvH/KaeUt8IphfJSiqyMEtaWdtNZi4l9SY3Z\nkkVjmpiYLJuJ2S7mjLta3JXxqtobjbEXmnhjNl3c1LjUZaubzrVzAkMKpYO1UHqgvB6gcHp4Obwc\n75kXD8s5Nk/y/Vw2T/5/ysvT/0V//CKZTCYAADxsu98fAABAR2kDgBFKGwCMUNoAYITSBgAjlDYA\nGInm+oIffPEp6f8UFtTukM57/MgZ+e7o0YekXN/CkJR75umvy3cr5l6+IOVi+3fKZ86vr0m5heEZ\n7bxUWsodfvYlKbcVP/rNX6Vcf7729phabpRyeava92JyQ/scfvjcw1JuK5594WdSrvP1N6Rc6yNN\nUu7EyaNSLoQQ+m9pP1fnfv5T+UzF6YPfkXL7v/qYdmBaf9sWzY5Juc6RuJS7cvl8ZPOf8dIGACOU\nNgAYobQBwAilDQBGKG0AMEJpA4ARShsAjFDaAGAk58M14wOdUq5kbI+Umzn+Nfnuo1V7pdzNJW0g\nJdveHBqWcpXbjshnPrKzUsoly3dLubmJUfnubLue0L49uyPlUm4xf13KRUr3SbmC6KfmHv5v+v/+\nHym3nrcs5Z78vja0trxUJuVCCOH377wtZ7Mp/+FTUq5o1yEpN58qku/+9+BlKXc93i+fuRkvbQAw\nQmkDgBFKGwCMUNoAYITSBgAjlDYAGKG0AcAIpQ0ARihtADBCaQOAkZyPsa8saLvQVlKLUq44Ka2c\nDCGEEC3bJeUaqublM7Pp5fbrUq76/Y/lM9+qe1TKxfZr482xjLZXMRdm0vlSbnG7dt7cknZeamVC\nykXnk9rFOTCT1n69wDe+eVzKnXpUG2N/7scvSrkQQhi8rX/fZtO+lhNSbrWxXsqlOrrlu5MJ7e+c\nHPvsncNLGwCMUNoAYITSBgAjlDYAGKG0AcAIpQ0ARihtADBCaQOAEUobAIzkfCKy5oESKZcYrZBy\nN+PX5LsbrrRpdxfqU5bZdHuhRspdWRiWz7zbqS0W3XugQMq1PqhNEeZEpbZQtaFQm2xrLtcWAK+k\nV6Vcck2barsqpbamtUVbPvzlk9rPwDv92hLeC796VcqFEELbGW0690ZPdicnI1Hte7twrE/KTcTf\nl+8ejWsT4CXrn8hnbsZLGwCMUNoAYITSBgAjlDYAGKG0AcAIpQ0ARihtADBCaQOAEUobAIzkfCKy\npUXbUTdaqf37MT2Vlu/uGOmVckUl4pLBLCup03ZYlk1oE14hhLCempRy02ltR2R396x8d7btjdyV\ncski7esXrVyXcstLESlXNaxNTuZiIrKpplrK9fd0SbmOP/VIuZrqPCkXQghnH/uSlPvg9UvymYod\n4x1SbnL0npSb69UnIgsWtd2d26Mp+czNeGkDgBFKGwCMUNoAYITSBgAjlDYAGKG0AcAIpQ0ARiht\nADBCaQOAkUgmk9v9iJFI5P4sYAQAc5lM5lPjuby0AcAIpQ0ARihtADBCaQOAEUobAIxQ2gBghNIG\nACOUNgAYobQBwAilDQBGKG0AMEJpA4ARShsAjFDaAGCE0gYAI5Q2ABihtAHACKUNAEYobQAwQmkD\ngJFori944/KrUm77dJ6Uax+9Ld/d/tZHUu5g23Ep95OXnpfvVhw++0MpN9Q7KJ+ZSqxIuf1tB6Xc\nsdNHpNzvXviWlNuK9ot/lnJVdaVSrr6iVspNJxal3N/+2SXlvv38d6XcVvzytSUptzE/IuUSgwkp\nN3M3JeVCCKGkeF7KnTt/Vj5Tcf6pZ6RcxdW7Um5obEa+e2VqVMrVtVXJZ27GSxsAjFDaAGCE0gYA\nI5Q2ABihtAHACKUNAEYobQAwQmkDgBFKGwCM5HwiMjo7K+VaT56RcvVTh+S7L/z6t1Lu6sSQfGY2\nPfmVU1KuY1uhfOZH77ZLuYl/vCfl+iam5Luzrf9OXMq98pcxKTcweUfKpdLaJF/9rjIplwuN4zel\nXGR6Xcolx7TP9e6b2hRhCCGsxiJyNptWZnZLueH6Eim3u7RVvju/aULKFYRe+czNeGkDgBFKGwCM\nUNoAYITSBgAjlDYAGKG0AcAIpQ0ARihtADBCaQOAkZxPRPbG70m5Nm04KYRYhXx3fa22B7H9qjZF\nmG1NxeNSLnasRj7zgehhKTfe1SflEre0PZs9Umpr/vDHbinX9Yn2Md6Jz0m5utZqLdf4kJTLheZ7\nq1JufkTbGdr0sTYVHJ3R9yXO5jfK2WyKt2h7TZ8I2td5rVTbGRpCCJMDk1Ju27XPPk3LSxsAjFDa\nAGCE0gYAI5Q2ABihtAHACKUNAEYobQAwQmkDgBFKGwCMUNoAYCTnY+xL69NS7krfsJSrrdTG4kMI\n4Vjrg1JuI08b9e28eEO+W5G49S8p17y3Xj7z+OdjUm62vEnKfTigLbl985IU25JmcUz86e89LuUa\nKvZJuczB7VIu0aWNdL/yi3NSbisaRrWvS2pS+1UARSPaqPbUtL5k+nMpfeQ9m76wodVa8doJKVdd\nlpTvrqh5W8p9MLJHPnMzXtoAYITSBgAjlDYAGKG0AcAIpQ0ARihtADBCaQOAEUobAIxQ2gBgJOcT\nkZH8jJS71qOthh3YWS7fXbBnQ8o9EdOW4XZefE2+W7F4a1TKzW2syWc21GlLgA817ZByZbEWKffi\npfek3FaU7UtLucpabZpvsWpAy8W1LdPXBqekXC5MTyWk3Eqv9i4rH1uSchWlY1IuhBDmCg/I2Ww6\nUNwm5RpOp6Tc/LtF8t035pulXPWytmT6f+GlDQBGKG0AMEJpA4ARShsAjFDaAGCE0gYAI5Q2ABih\ntAHACKUNAEYimYw2sQgAuP94aQOAEUobAIxQ2gBghNIGACOUNgAYobQBwAilDQBGKG0AMEJpA4AR\nShsAjFDaAGCE0gYAI5Q2ABihtAHACKUNAEYobQAwQmkDgBFKGwCMUNoAYITSBgAj/wVnrbn9dPBz\nIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f3a74ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How do the filters in the first layer look like?\n",
    "\n",
    "plot_mat(CW1.get_value(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iii = predict.maker.inputs[0]\n",
    "X = iii.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a function that shows how the network processes an image\n",
    "\n",
    "middle_layers_computer = theano.function([X], [\n",
    "        X,\n",
    "        after_C1,\n",
    "        after_P1,\n",
    "        after_C2,\n",
    "        after_P2\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACWCAYAAAAVI9lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f3adf5a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACuCAYAAAD9ClyMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f45205780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACsCAYAAACwwv2HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f3abc5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADnCAYAAAA+arwrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f3aba9550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADkCAYAAABTyXWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nobQBwBBKGwAMobQBwBBKGwAM+T/sMshI3x09HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f3ad61048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num=4\n",
    "\n",
    "middle_layers = middle_layers_computer(X_test_value[img_num:img_num+1])\n",
    "\n",
    "for ml, name in zip(middle_layers, ['X', 'C1', 'P1', 'C2', 'P2']):\n",
    "    plot_mat(ml.transpose(1,0,2,3), cmap='gray')\n",
    "    title(name)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
