{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 740M\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import theano\n",
    "import theano.tensor.signal.downsample\n",
    "from common.plotting import plot_mat\n",
    "from utils import *\n",
    "import time\n",
    "\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prepare_cifar10 import *\n",
    "\n",
    "cifar = prepare_cifar10()\n",
    "\n",
    "cifar_train = cifar.train\n",
    "cifar_train_stream = cifar.train_stream\n",
    "                                               \n",
    "cifar_validation = cifar.validation\n",
    "cifar_validation_stream = cifar.validation_stream\n",
    "\n",
    "cifar_test = cifar.test\n",
    "cifar_test_stream = cifar.test_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def conv2D(num_in_filters, num_out_filters, kernel_size, name = None):\n",
    "    name = name if name else fresh_name(\"?\")\n",
    "        \n",
    "    weights_shape = (num_out_filters, num_in_filters, kernel_size, kernel_size)\n",
    "    weights_name = \"{}.weights\".format(name)\n",
    "    weights = theano.shared(np.zeros(weights_shape, dtype = 'float32'), name = weights_name)\n",
    "    weights.tag.initializer = IsotropicGaussian(0.05)\n",
    "    \n",
    "    biases_shape = (num_out_filters,)\n",
    "    biases_name = \"{}.biases\".format(name)\n",
    "    biases = theano.shared(np.zeros(biases_shape, dtype='float32'), biases_name)\n",
    "    biases.tag.initializer = Constant(0.0)\n",
    "    \n",
    "    def fprop(X):\n",
    "        return theano.tensor.nnet.conv2d(X, weights) + biases.dimshuffle('x', 0, 'x', 'x')\n",
    "    \n",
    "    fprop.params = [weights, biases]\n",
    "    \n",
    "    return fprop\n",
    "\n",
    "def relu(name = fresh_name(\"?\")):\n",
    "    def fprop(X):\n",
    "        return theano.tensor.maximum(0.0, X)\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def max_pool_2d(kernel_size):\n",
    "    def fprop(X):\n",
    "        kernel_shape = (kernel_size, kernel_size)\n",
    "        return theano.tensor.signal.downsample.max_pool_2d(X, kernel_shape, ignore_border = True)\n",
    "\n",
    "    return fprop\n",
    "\n",
    "def flatten(name = None):\n",
    "    def fprop(X):\n",
    "        return X.flatten(2)\n",
    "\n",
    "    return fprop\n",
    "\n",
    "def dropout(prob = 0.5, name = None):\n",
    "    rng = theano.tensor.shared_randomstreams.RandomStreams(random.randint(1, 748978023))\n",
    "    rprop = 1 - prob\n",
    "    \n",
    "    def fprop(X):\n",
    "        return X * rng.binomial(X.shape, p = rprop, dtype = \"float32\")\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def xaffine(num_inputs, num_outputs, name = None):    \n",
    "    name = name if name else fresh_name(\"?\")\n",
    "    \n",
    "    weights_shape = (num_inputs, num_outputs)\n",
    "    weights_name = \"{}.weights\".format(name)\n",
    "    weights = theano.shared(np.zeros(weights_shape, dtype='float32'), name = weights_name)\n",
    "    weights.tag.initializer = IsotropicGaussian(0.05)\n",
    "    \n",
    "    biases_shape = (num_outputs, )\n",
    "    biases_name = \"{}.biases\".format(name)\n",
    "    biases = theano.shared(np.zeros(biases_shape, dtype='float32'), name = biases_name)\n",
    "    biases.tag.initializer = Constant(0.0)\n",
    "    \n",
    "    def fprop(X):\n",
    "        return theano.tensor.dot(X, weights) + biases.dimshuffle('x', 0)\n",
    "\n",
    "    fprop.params = [weights, biases]\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def maxout(num_inputs, num_outputs, degree, name = None):\n",
    "    name = name if name else fresh_name(\"?\")\n",
    "    \n",
    "    weights_shape = (num_outputs, num_inputs, degree)\n",
    "    weights_name = \"{}.weights\".format(name)\n",
    "    weights = theano.shared(np.zeros(weights_shape, dtype='float32'), name = weights_name)\n",
    "    weights.tag.initializer = IsotropicGaussian(0.05)\n",
    "    \n",
    "    biases_shape = (num_outputs, degree)\n",
    "    biases_name = \"{}.biases\".format(name)\n",
    "    biases = theano.shared(np.zeros(biases_shape, dtype='float32'), name = biases_name)\n",
    "    biases.tag.initializer = Constant(0.0)\n",
    "    \n",
    "    def fprop(X):\n",
    "        return theano.tensor.max(theano.tensor.dot(X, weights) + biases.dimshuffle('x', 0, 1), axis = 2)\n",
    "    \n",
    "    fprop.params = [weights, biases]\n",
    "    \n",
    "    return fprop\n",
    "    \n",
    "def softmax():\n",
    "    def fprop(X):\n",
    "        return theano.tensor.nnet.softmax(X)\n",
    "\n",
    "    return fprop\n",
    "    \n",
    "def compose(*args):\n",
    "    def fprop(X):\n",
    "        for arg in args:\n",
    "            X = arg(X)\n",
    "        return X\n",
    "    \n",
    "    params = []\n",
    "\n",
    "    for arg in args:\n",
    "        try:\n",
    "            params += arg.params\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    \n",
    "    if params != []:\n",
    "        fprop.params = params\n",
    "    \n",
    "    return fprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile(template):\n",
    "    X = theano.tensor.tensor4('X', dtype = 'float32')\n",
    "    Y = theano.tensor.matrix('Y', dtype = 'uint8')\n",
    "    \n",
    "    model_parameters = template.params\n",
    "\n",
    "    log_probs = template(X)\n",
    "\n",
    "    predictions = theano.tensor.argmax(log_probs, axis = 1)\n",
    "\n",
    "    error_rate = theano.tensor.neq(predictions,Y.ravel()).mean()\n",
    "    nll = - theano.tensor.log(log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()\n",
    "\n",
    "    weight_decay = 0.0\n",
    "    for p in model_parameters:\n",
    "        if p.name.endswith('weights'):\n",
    "            weight_decay = weight_decay + 1e-3 * (p ** 2).sum()\n",
    "\n",
    "    cost = nll + weight_decay\n",
    "    \n",
    "    learn_rate = theano.tensor.scalar('learn_rate', dtype = 'float32')\n",
    "    momentum = theano.tensor.scalar('momentum', dtype = 'float32')\n",
    "\n",
    "    # Theano will compute the gradients for us\n",
    "    gradients = theano.grad(cost, model_parameters)\n",
    "\n",
    "    #initialize storage for momentum\n",
    "    velocities = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in model_parameters]\n",
    "    \n",
    "    updates = []\n",
    "\n",
    "    for p, g, v in zip(model_parameters, gradients, velocities):\n",
    "        v_new = momentum * v - learn_rate * g\n",
    "        p_new = p + v_new\n",
    "        updates += [(v, v_new), (p, p_new)]\n",
    "            \n",
    "    def step_ex(X, Y, learn_rate, momentum):\n",
    "        return step(X, Y, learn_rate, momentum)\n",
    "    \n",
    "    def init_parameters():\n",
    "        rng = numpy.random.RandomState(1234)\n",
    "        \n",
    "        for p in model_parameters:\n",
    "            p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "            \n",
    "        for v in velocities:\n",
    "            v.set_value(np.zeros_like(v.get_value()))\n",
    "            \n",
    "    step = theano.function(\n",
    "        [X, Y, learn_rate, momentum],\n",
    "        [cost, error_rate, nll, weight_decay],\n",
    "        updates = updates, \n",
    "        allow_input_downcast = True)\n",
    "            \n",
    "    predict = theano.function([X], predictions)\n",
    "    \n",
    "    init_parameters()\n",
    "    \n",
    "    class Network:\n",
    "        def snapshot(self):\n",
    "            return [p.get_value(borrow = False) for p in self.params]\n",
    "    \n",
    "        def load(self, snapshot):\n",
    "            for p, s in zip(self.params, snapshot):\n",
    "                p.set_value(s, borrow = False)\n",
    "    \n",
    "    network = Network()\n",
    "    network.step = step_ex\n",
    "    network.predict = predict\n",
    "    network.params = model_parameters\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(network, learn_rate0, momentum):\n",
    "    batch = 0\n",
    "    epoch = 0\n",
    "\n",
    "    best_valid_error_rate = np.inf\n",
    "    best_params = network.snapshot()\n",
    "    best_params_epoch = 0\n",
    "\n",
    "    train_erros = []\n",
    "    train_loss = []\n",
    "    train_nll = []\n",
    "    validation_errors = []\n",
    "\n",
    "    number_of_epochs = 3\n",
    "    patience_expansion = 1.5\n",
    "\n",
    "    # training loop\n",
    "    try:\n",
    "        start = time.time()\n",
    "        \n",
    "        while epoch < number_of_epochs: #This loop goes over epochs\n",
    "            epoch += 1\n",
    "            #First train on all data from this batch\n",
    "\n",
    "            epoch_start_batch = batch\n",
    "\n",
    "            for X_batch, Y_batch in cifar_train_stream.get_epoch_iterator(): \n",
    "                batch += 1\n",
    "\n",
    "                # learn_rate = learn_rate0 * (1 - np.tanh(batch * 0.549306 / 2000))\n",
    "                \n",
    "                K = 2000\n",
    "                learn_rate = learn_rate0 * K / np.maximum(K, batch)\n",
    "                \n",
    "                L, err_rate, nll, wdec = network.step(X_batch, Y_batch, learn_rate, momentum)\n",
    "\n",
    "                train_loss.append((batch, L))\n",
    "                train_erros.append((batch, err_rate))\n",
    "                train_nll.append((batch, nll))\n",
    "\n",
    "                if False and batch % 100 == 0:\n",
    "                    end = time.time()\n",
    "                    elapsed = end - start\n",
    "                    start = end\n",
    "                    format = \"At minibatch %d, batch loss %f, batch nll %f, batch error rate %f%%, time %.2fms\"\n",
    "                    print(format % (batch, L, nll, err_rate * 100, elapsed / Y_batch.shape[0] * 1000), flush = True)\n",
    "\n",
    "            # After an epoch compute validation error\n",
    "            val_error_rate = compute_error_rate(cifar_validation_stream, network.predict)\n",
    "            if val_error_rate < best_valid_error_rate:\n",
    "                number_of_epochs = np.maximum(number_of_epochs, epoch * patience_expansion + 1)\n",
    "                best_valid_error_rate = val_error_rate\n",
    "                best_params = network.snapshot()\n",
    "                best_params_epoch = epoch\n",
    "            validation_errors.append((batch, val_error_rate))\n",
    "\n",
    "            print(\"After epoch %d: valid_err_rate: %f%% currently going to do %d epochs\" %(\n",
    "                epoch, val_error_rate * 100, number_of_epochs))\n",
    "            print(\"After epoch %d: averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" %(\n",
    "                epoch, np.mean(np.asarray(train_erros)[epoch_start_batch:, 1]) * 100, \n",
    "                np.mean(np.asarray(train_nll)[epoch_start_batch:, 1]),\n",
    "                np.mean(np.asarray(train_loss)[epoch_start_batch:, 1])), flush = True)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Setting network parameters from after epoch %d\" %(best_params_epoch))\n",
    "        network.load(best_params)\n",
    "        \n",
    "        subplot(2,1,1)\n",
    "        train_nll_a = np.array(train_nll)\n",
    "        semilogy(train_nll_a[:,0], train_nll_a[:,1], label='batch train nll')\n",
    "        legend()\n",
    "\n",
    "        subplot(2,1,2)\n",
    "        train_erros_a = np.array(train_erros)\n",
    "        plot(train_erros_a[:,0], train_erros_a[:,1], label='batch train error rate')\n",
    "        validation_errors_a = np.array(validation_errors)\n",
    "        plot(validation_errors_a[:,0], validation_errors_a[:,1], label='validation error rate', color='r')\n",
    "        ylim(0,0.2)\n",
    "        legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling... DONE\n",
      "After epoch 1: valid_err_rate: 71.470000% currently going to do 3 epochs\n",
      "After epoch 1: averaged train_err_rate: 80.487500% averaged train nll: 2.153232 averaged train loss: 2.960059\n",
      "After epoch 2: valid_err_rate: 64.400000% currently going to do 4 epochs\n",
      "After epoch 2: averaged train_err_rate: 66.752500% averaged train nll: 1.798502 averaged train loss: 2.524087\n",
      "After epoch 3: valid_err_rate: 61.150000% currently going to do 5 epochs\n",
      "After epoch 3: averaged train_err_rate: 61.545000% averaged train nll: 1.671884 averaged train loss: 2.347953\n",
      "After epoch 4: valid_err_rate: 60.220000% currently going to do 7 epochs\n",
      "After epoch 4: averaged train_err_rate: 59.927500% averaged train nll: 1.617996 averaged train loss: 2.263514\n",
      "After epoch 5: valid_err_rate: 58.460000% currently going to do 8 epochs\n",
      "After epoch 5: averaged train_err_rate: 58.320000% averaged train nll: 1.585686 averaged train loss: 2.209423\n",
      "After epoch 6: valid_err_rate: 57.660000% currently going to do 10 epochs\n",
      "After epoch 6: averaged train_err_rate: 57.310000% averaged train nll: 1.560451 averaged train loss: 2.167668\n",
      "After epoch 7: valid_err_rate: 56.640000% currently going to do 11 epochs\n",
      "After epoch 7: averaged train_err_rate: 57.057500% averaged train nll: 1.546062 averaged train loss: 2.139842\n",
      "After epoch 8: valid_err_rate: 56.790000% currently going to do 11 epochs\n",
      "After epoch 8: averaged train_err_rate: 56.400000% averaged train nll: 1.532650 averaged train loss: 2.115277\n",
      "After epoch 9: valid_err_rate: 56.270000% currently going to do 14 epochs\n",
      "After epoch 9: averaged train_err_rate: 55.405000% averaged train nll: 1.517884 averaged train loss: 2.091014\n",
      "After epoch 10: valid_err_rate: 55.540000% currently going to do 16 epochs\n",
      "After epoch 10: averaged train_err_rate: 55.342500% averaged train nll: 1.506947 averaged train loss: 2.071856\n",
      "After epoch 11: valid_err_rate: 55.090000% currently going to do 17 epochs\n",
      "After epoch 11: averaged train_err_rate: 54.832500% averaged train nll: 1.497302 averaged train loss: 2.054954\n",
      "After epoch 12: valid_err_rate: 54.970000% currently going to do 19 epochs\n",
      "After epoch 12: averaged train_err_rate: 54.495000% averaged train nll: 1.491938 averaged train loss: 2.043075\n",
      "After epoch 13: valid_err_rate: 55.190000% currently going to do 19 epochs\n",
      "After epoch 13: averaged train_err_rate: 54.177500% averaged train nll: 1.480373 averaged train loss: 2.025660\n",
      "After epoch 14: valid_err_rate: 54.350000% currently going to do 22 epochs\n",
      "After epoch 14: averaged train_err_rate: 54.045000% averaged train nll: 1.474579 averaged train loss: 2.014531\n",
      "After epoch 15: valid_err_rate: 54.530000% currently going to do 22 epochs\n",
      "After epoch 15: averaged train_err_rate: 53.955000% averaged train nll: 1.471859 averaged train loss: 2.006971\n",
      "After epoch 16: valid_err_rate: 53.800000% currently going to do 25 epochs\n",
      "After epoch 16: averaged train_err_rate: 53.010000% averaged train nll: 1.463298 averaged train loss: 1.993948\n",
      "Setting network parameters from after epoch 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAECCAYAAAAVYxsVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6628cd9978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "nn = compose(conv2D(3, 64, 7), \n",
    "             relu(), \n",
    "             max_pool_2d(2),\n",
    "             conv2D(64, 32, 3), \n",
    "             relu(), \n",
    "             max_pool_2d(2),\n",
    "             flatten(),\n",
    "             dropout(),\n",
    "             maxout(800, 128, 3),\n",
    "             dropout(),\n",
    "             maxout(128, 10, 5),\n",
    "             softmax()\n",
    "            )\n",
    "\n",
    "print(\"Compiling...\", end = \" \", flush = True)\n",
    "network = compile(nn)\n",
    "print(\"DONE\", flush = True)\n",
    "\n",
    "train(network, 4e-3, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Test error rate is %f%%\" %(compute_error_rate(cifar_test_stream, network.predict) * 100.0,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How do the filters in the first layer look like?\n",
    "\n",
    "for param in network.params:\n",
    "    if param.name.endswith('weights'):\n",
    "        plot_mat(param.get_value(), cmap='gray')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iii = network.predict.maker.inputs[0]\n",
    "X = iii.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a function that shows how the network processes an image\n",
    "\n",
    "middle_layers_computer = theano.function([X], [\n",
    "        X,\n",
    "        after_C1,\n",
    "        after_P1,\n",
    "        after_C2,\n",
    "        after_P2\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_num=4\n",
    "\n",
    "middle_layers = middle_layers_computer(X_test_value[img_num:img_num+1])\n",
    "\n",
    "for ml, name in zip(middle_layers, ['X', 'C1', 'P1', 'C2', 'P2']):\n",
    "    plot_mat(ml.transpose(1,0,2,3), cmap='gray')\n",
    "    title(name)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
